
\section{Simulations}\label{sec-sim}


To assess the finite sample performance of the methods from Sections \ref{sec-test-shape} and \ref{sec-test-equality}, we conduct a number of simulations. We first investigate the test procedure from Section \ref{sec-test-shape}. The simulation design is set up to mimic the situation in the application example of Section \ref{subsec-data-1}: We generate data from the model $Y_t = m(t/T) + \varepsilon_t$ for different time series lengths $T$. The errors $\varepsilon_t$ are drawn from the AR(1) process $\varepsilon_t = a \varepsilon_{t-1} + \eta_t$, where $\eta_t$ are independent and normally distributed with mean $0$ and variance $\sigma_\eta^2$. We set $a = 0.267$ and $\sigma_\eta^2 = 0.35$, thus matching the estimated values obtained in the application of Section \ref{subsec-data-1}. To simulate data under the null $H_0: m^\prime = 0$, we let $m$ be a constant function. In particular, we set $m = 0$ without loss of generality. To generate data under the alternative, we consider the trend functions $m(u) = \beta \, (u - 0.6) \, 1(0.6 \le u \le 1)$ with $\beta = 1.25, 1.875, 2.5$. These functions are broken lines with a kink at $u = 0.6$ and different slopes $\beta$. The slope parameter $\beta$ corresponds to a trend with the value $m(1) = 0.4 \, \beta$ at the right endpoint $u = 1$. We thus consider broken lines with the values $m(1) = 0.5, 0.75, 1.0$. Inspecting the middle panel of Figure \ref{plot-results-app1}, the broken line with the slope $\beta = 2.5$ can be seen to resemble the local linear trend estimates in the real-data example of Section \ref{subsec-data-1} (where we neglect the nonlinearities of the local linear fits at the beginning of the observation period), whereas the trend functions with smaller values of slope $\beta = 1.25, 1.875$ are closer to the null making it harder for our test to detect the difference.

\begin{table}[t]
\footnotesize{
\begin{center}
\caption{Size of the multiscale test from Section \ref{sec-test-shape} for different sample sizes $T$ and nominal sizes $\alpha$.}
\label{tab:size_shape}
\renewcommand{\arraystretch}{1.2}
\input{Plots/sizetable_ll_testing_constant}
\end{center}}
\end{table}

\begin{table}[t]
\footnotesize{
\begin{center}
\caption{Power of the multiscale test from Section \ref{sec-test-shape} for different sample sizes $T$ and nominal sizes $\alpha$. Each panel corresponds to a different slope parameter $\beta$.}\label{tab:power_shape}
\begin{subtable}[b]{0.32\textwidth}
\centering
\caption{$\beta = 1.25$}\label{tab:power_050_ll_shape}
\renewcommand{\arraystretch}{1.2}
\input{Plots/powertable_50_ll_testing_constant}
\end{subtable}
\begin{subtable}[b]{0.32\textwidth}
\centering
\caption{$\beta = 1.875$}\label{tab:power_075_ll_shape}
\renewcommand{\arraystretch}{1.2}
\input{Plots/powertable_75_ll_testing_constant}
\end{subtable}
\begin{subtable}[b]{0.32\textwidth}
\centering
\caption{$\beta = 2.5$}\label{tab:power_100_ll_shape}
\renewcommand{\arraystretch}{1.2}
\input{Plots/powertable_100_ll_testing_constant}
\end{subtable}
\end{center}}
\end{table}

To implement our test methods, we use the Epanechnikov kernel $K(x) = 0.75 \, (1 - x^2) \, 1(|x| \le 1)$ and define the set $\mathcal{G}_T$ of location-scale points $(u,h)$ to be 
\begin{equation}\label{grid-sim-app}
\mathcal{G}_T = \{(u, h): u = \frac{5k}{T} \text{ and } h = \frac{3+5l}{T} \text{ for some } k, l \in \mathbb{N}, k \le \frac{T}{5}, l \le \frac{T}{20}\}. 
\end{equation}
To estimate the long-run error variance $\sigma^2$, we employ the estimation procedure from Section \ref{subsec-error-var-ar}, setting the tuning parameters $L_1$ and $L_2$ to $[\sqrt{T}]$ and $[2\sqrt{T}]$ respectively. The critical values are computed by simulating $1000$ values of the statistic $\Phi^\prime_T$ defined in Section \ref{subsec-test-shape-test} and computing their empirical $(1-\alpha)$ quantiles $q_T^\prime(\alpha)$. 


Tables \ref{tab:size_shape} and \ref{tab:power_shape} report the simulation results for the sample sizes $T=250,350,500, 1000$ and the confidence levels $\alpha = 0.01, 0.05, 0.10$. The sample size $T = 350$ is approximately equal to the time series length $359$ in the real-data example of Section \ref{subsec-data-1}. To produce our simulation results, we generate $S=10000$ samples for each time series length $T$ and carry out the multiscale test for each simulated sample. The entries of Tables \ref{tab:size_shape} and \ref{tab:power_shape} are computed as the number of simulations in which the test rejects divided by the total number of simulations. As can be seen from Table \ref{tab:size_shape}, the actual size of the test is fairly close to the nominal target $\alpha$ even for small values of $T$. Hence, the test has approximately the correct size. Inspecting Table \ref{tab:power_shape}, one can further see that the test has reasonable power properties. For the smallest value $\beta = 1.25$, the deviation from the null is quite small, making it hard for the test to detect the alternative. As a consequence, the power is only moderate in cases $T=250$ and $T=350$. When we move further away from the null by increasing the slope parameter $\beta$, the power of the test quickly increases. For the slope $\beta =2.5$ and sample size $T=350$, which are the values that resemble the real-life data the most, the power of the test is fairly large. In addition, it can also be seen to quickly get larger as the sample size grows. 
 


\begin{table}[t]
\footnotesize{
\begin{center}
\caption{Size of the multiscale test from Section \ref{sec-test-equality} for 15 time series, different sample sizes $T$ and nominal sizes $\alpha$.}
\label{tab:size_equality}
\renewcommand{\arraystretch}{1.2}
\input{Plots/15_stations_sizetable_method_ll}
\end{center}}
\end{table}

\begin{table}[t]
\footnotesize{
\begin{center}
\caption{Power of the multiscale test from Section \ref{sec-test-equality} for different sample sizes $T$ and nominal sizes $\alpha$. Each panel corresponds to a different slope parameter $\beta$.}\label{tab:power_equality}
\begin{subtable}[b]{0.32\textwidth}
\centering
\caption{$\beta = 0.75$}\label{tab:power_75_equality}
\renewcommand{\arraystretch}{1.2}
\input{Plots/15_stations_powertable_method_ll_with_b_75}
\end{subtable}
\begin{subtable}[b]{0.32\textwidth}
\centering
\caption{$\beta = 1.00$}\label{tab:power_100_equality}
\renewcommand{\arraystretch}{1.2}
\input{Plots/15_stations_powertable_method_ll_with_b_100}
\end{subtable}
%\begin{subtable}[b]{0.32\textwidth}
%\centering
%\caption{$\beta = 1.25$}\label{tab:power_125_equality}
%\renewcommand{\arraystretch}{1.2}
%\input{Plots/15_stations_powertable_method_ll_with_b_125}
%\end{subtable}
\end{center}}
\end{table}


%\begin{table}[t]
%\footnotesize{
%\begin{center}
%\caption{Clustering results for Section \ref{sec-test-equality} for different sample sizes $T$ and nominal sizes $\alpha$.}\label{tab:clustering_results}
%\begin{subtable}[b]{0.48\textwidth}
%\centering
%\caption{Correct number of groups}\label{tab:clustering_number_of_groups}
%\renewcommand{\arraystretch}{1.2}
%\input{Plots/15_stations_number_of_groups_method_ll}
%\end{subtable}
%\begin{subtable}[b]{0.48\textwidth}
%\centering
%\caption{Correct grouping}\label{tab:clustering_groups}
%\renewcommand{\arraystretch}{1.2}
%\input{Plots/15_stations_groups_method_ll}
%\end{subtable}
%\end{center}}
%\end{table}


We next turn to the test methods from Section \ref{sec-test-equality}. The simulation design extends the setup from above. We generate data from the model $Y_{it} = m_i(t/T) + \varepsilon_{it}$, where the number of time series is set to $n = 15$ and we consider different time series lengths $T$. For each $i$, the errors $\varepsilon_{it}$ are drawn from the AR(1) model $\varepsilon_{it} = a \varepsilon_{i,t-1} + \eta_{it}$, where as before $a = 0.267$ and the innovations $\eta_{it}$ are i.i.d. normally distributed with mean $0$ and variance $0.35$. To generate data under the null $H_0: m_1 = \ldots = m_n$, we let $m_i = 0$ for all $i$ without loss of generality. To produce data under the alternative, we define $m_1(u) = \beta \, (u - 0.5) $ with $\beta = 0.75, 1, 1.25$ and set $m_i = 0$ for all $i \ne 1$. Hence, all trend functions are the same except for $m_1$ which is an increasing linear function that resembles the local linear trend estimates in the application in Section \ref{subsec-data-2}. 


The test is implemented analogously as above. As before, we work with an Epanechnikov kernel and the grid $\mathcal{G}_T$ defined in \eqref{grid-sim-app}. However, due to computational restrictions we make two important adjustments to the procedure described above. First, we run $S = 1000$ simulations instead of $10000$ in the previous simulations. Second, we make an assumption that the long run variance $\sigma_i^2$ does not depend on $i$, i.e. $\sigma_i^2 = \sigma^2$ $\forall i\in \{1, \ldots, n\}$. Since all time series were generated from the same model, this is a valid assumption, which leads to estimates of each $\sigma_i$ to be equal $\widehat{\sigma}^2 = (\sum_{i = 1}^n\widehat{\sigma_i^2})/n$ where $\sigma_i^2$ are calculated by the estimation procedure from Section \ref{subsec-error-var-ar} with $L_1 = [\sqrt{T}]$ and $L_2 = [2 \sqrt{T}]$. As a result, the gaussian statistics $\widehat{\Psi}_{ij, T}$ do not depend on $\widehat{\sigma}_i$ and $\widehat{\sigma}_j$, and hence, we do not need to recalculate the statistic distribution for each of $1000$ samples. This leads to significant increase in running time.

The simulation results are reported in Tables \ref{tab:size_equality} and \ref{tab:power_equality}.

As can be seen from Table \ref{tab:power_equality}, the overall performance of our method is relatively high. For example, for the largest sample size considered $T = 1000$, the empirical power is essentially always $1.00$ for all the alternatives considered. Moreover, for the largest value of the slope $\beta = 1.25$ the power is $1.00$ even for smaller sample sizes $T = 400, 500$ due to the fact that in this case the trend function is sufficiently different from the null, therefore, it is easy for our test to detect this difference. For the values of the slope $\beta = 1.00$ and time series length $T = 400$, which are closest to the real-life data from Section \ref{subsec-data-2}, the test has reasonable power for all values of $\alpha$.


We finally investigate the finite sample performance of the clustering algorithm from Section \ref{subsec-test-equality-clustering}. To do so, we partition the $n = 15$ time series into $N=3$ groups, each containing $5$ time series. Specifically, we set $G_1 = \{1,\ldots,5\}$, $G_2 = \{6,\ldots,10\}$ and $G_3 =  \{11,\ldots,15\}$. Moreover, we define the group-specific trend functions $g_1$, $g_2$ and $g_3$ by $g_1(u) = 0$, $g_2(u) = 1 \cdot (u - 0.5)$ and $g_3(u) =  (- 1) \cdot (u - 0.5)$. In order to compute our estimators of the groups $G_1$, $G_2$, $G_3$ and their number $N = 3$, we use the same implementation as before. The estimation results are reported in Tables ?? and ??. [\textcolor{red}{Discuss results!}]   




\section{Applications}\label{sec-data}


In what follows, we illustrate the multiscale methods from Sections \ref{sec-test-shape} and \ref{sec-test-equality} by two real-data examples. In the first example, we apply the test method from Section \ref{sec-test-shape} to a long time series of temperature data from Central England. In the second, we analyse a sample of temperature time series from 34 different weather stations in Great Britain with the help of the methods from Section \ref{sec-test-equality}. 


\begin{figure}[t]
\centering
\includegraphics[width=0.8\textwidth]{Plots/threegraphics_testing_constant_method_ll.pdf}
\vspace{0.2cm}

\caption{Summary of the application results from Section \ref{subsec-data-1}. The upper panel shows the Central England mean temperature time series. The middle panel depicts local linear kernel estimates of the time trend for a number of different bandwidths $h$. The lower panel presents the minimal intervals in the set $\Pi_T^+$ produced by the multiscale test.}\label{plot-results-app1}
\end{figure}


\subsection{Analysis of Central England temperature data}\label{subsec-data-1} 


The analysis of time trends in long temperature records is an important task in climatology. Information on the shape of the trend is needed in order to better understand long-term climate variability. The Central England temperature record is the longest instrumental temperature time series in the world. It is a valuable asset for analysing climate variability over the last few hundred years. The data is publicly available on the webpage of the UK Met Office, a United Kingdom national weather service. A detailed description of the data can be found in \cite{Parker1992}. For our analysis, we use the dataset of yearly mean temperatures which consists of $T=359$ observations covering the years from $1659$ to $2017$. We assume that the data follow the nonparametric trend model 
\[ Y_t = m\Big(\frac{t}{T}\Big) + \varepsilon_t, \]
where $m$ is the unknown time trend of interest. The error process $\{ \varepsilon_t \}$ is supposed to have the AR(1) structure $\varepsilon_t = a \varepsilon_{t-1} + \eta_t$, where $\eta_t$ are i.i.d. innovations with mean $0$ and variance $\sigma_\eta^2$. As pointed out in \cite{Mudelsee2010}, this is the most widely used error model for discrete climate time series. We estimate the unknown parameters $a$ and $\sigma_\eta^2$ by the procedure from Section \ref{subsec-error-var-ar} which yields estimates $\widehat{a} \approx 0.267$ and $\widehat{\sigma}_\eta^2 \approx 0.35$. Our method can be easily extended to the case with AR(2) and AR(3) errors.


We use our multiscale method from Section \ref{sec-test-shape} to test the null hypothesis $H_0: m^\prime = 0$, that is, the hypothesis that $m$ is constant. To do so, we set the significance level to $\alpha = 0.05$ and implement the test in exactly the same way as in the simulations of Section \ref{sec-sim}. The results are presented in Figure \ref{plot-results-app1}. The upper panel shows the raw temperature time series, whereas the middle panel depicts local linear kernel estimates of the trend $m$ for different bandwidths $h$. As one can see, the shape of the estimated time trend strongly differs with the chosen bandwidth. When the bandwidth is very small, there are many local increases and decreases in the estimated trend. When the bandwidth is very large, most of these local variations get smoothed out. Hence, by themselves, the nonparametric fits do not give much information on whether the trend $m$ is increasing or decreasing in certain time regions. 


Our multiscale test provides this kind of information, which is summarized in the lower panel of Figure \ref{plot-results-app1}. The plot depicts the minimal intervals contained in the set $\Pi_T^+$ which is defined in Section \ref{subsec-test-shape-theo}. The set of intervals $\Pi_T^-$ is empty in the present case. The height at which a minimal interval $I_{u,h} = [u-h,u+h] \in \Pi_t^+$ is plotted indicates the value of the corresponding (additively corrected) test statistic $\widehat{\psi}^\prime_T(u,h) / \hat{\sigma} - \lambda(h)$. The dashed line specifies the critical value $q_T^\prime(\alpha)$, where $\alpha = 0.05$ as already mentioned above. According to Proposition \ref{prop-test-shape-2}, we can make the following simultaneous confidence statement about the collection of minimal intervals in $\Pi_T^+$. We can claim, with confidence of about $95\%$, that the trend function $m$ has some increase on each minimal interval. In particular, we can claim with this confidence that there has been some upward movement in the trend both on the interval from ?? to ?? and on the interval from ?? to 2017. 
%As the minimal intervals cover the time period from ?? to 2017, we can in particular claim with simultaneous confidence of at least $95\%$, that there has been some upward movement in the trend both in the interval from ?? and ?? from ?? onwards. 
On the other hand, as the set $\Pi_T^-$ is empty, there is no evidence of any downward movement of the trend.  


To sum up, our multiscale test provides evidence that there have been some upward movements in the trend in the course of the observation period from $1659$ to $2017$. In particular, we can claim with confidence of around $95\%$, that there has been some increase in the trend within the time window from $1951$ to $2017$. 




\subsection{Analysis of UK weather station data}\label{subsec-data-2} 

For the illustration of our method from Section \ref{sec-test-equality}, we use the dataset of monthly mean temperatures from $34$ different UK stations which consists of $T=298$ observations covering the years from $1986$ to $2017$. As in Section \ref{subsec-data-2}, the data is publicly available on the webpage of the UK Met Office. We assume that for each station $i, i \in \{1,\ldots, 34\}$ the data are generated by the following nonparametric trend model 
\[ Y_{it}^{\text{month} = j} = \alpha_i^j + m_i\Big(\frac{t}{T}\Big) + \varepsilon_{it}, \]
where $m_i$ are unknown time trends of interest, $j \in \{1, \ldots, 12\}$ denotes the month, $\alpha_i^j$ is a trend- and month-specific intercept and the error process $\{ \varepsilon_{it} \}$ is assumed to have an AR(1) structure $\varepsilon_{it} = a_i \varepsilon_{i,t-1} + \eta_{it}$. As previously, $\eta_{it}$ are i.i.d. innovations with mean $0$ and variance $\sigma_{\eta_i}^2$. For each $i$ we separately estimate the unknown parameters $a_i$ and $\sigma_{\eta_i}^2$  by the procedure described in Section \ref{subsec-error-var-ar}.


Before applying our method, we need to deseasonalize the data, that is, to subtract monthly means which are calculated for each $i$ and $j$ by $\widehat{\alpha}^j_i = T_j^{-1} \sum_{t = 1}^T Y_{it}^{\text{month} = j}$ with $T_j$ being a number of observations in a dataset corresponding to the month $j$. This produces variables $\widehat{Y}_{it} =  Y_{it}^{\text{month} = j} - \widehat{\alpha}_i^j$ that can be regarded as approximations of the unknown standardized variables $Y_{it}^o$ from Section \ref{subsec-test-equality-stat}. Deseasonalization does not change anything in terms of theory behind our method but helps us exclude the seasonal component from the data. 


In order to test the null hypothesis $H_0: m_1 = \ldots = m_{34}$ or, in other words, that trends from various weather stations do not differ significantly, we implement the test from Section \ref{sec-test-equality} identically to the simulations of Section \ref{sec-sim}. At significance level $\alpha = 0.05$ we do not reject the null hypothesis.


Figure \ref{plot-results-app2} presents one of the possible reasons for this result. Each of the panels of Figure \ref{plot-results-app2} corresponds to a different bandwidth $h$ used for local linear kernel estimates of the trends $m_i$. As can be seen, shapes of the estimated time trends depend heavily on the bandwidth but for a given bandwidth $h$ they look similar. Hence, our test do not detect significant difference in their shapes. 


To conclude, our multiscale test provides evidence that there is no significant difference in the trends from various UK weather stations in the course of the observation period from $1986$ to $2017$.

\begin{figure}[t]
\centering
\includegraphics[width=0.8\textwidth]{Plots/stations_data.pdf}
\vspace{0.2cm}
\caption{Kernel estimates of the time trends from Section \ref{subsec-data-2} for a number of different bandwidths. The upper panel, the middle panel and the lower panel depict the estimated trend functions for $h = 0.05$, $h = 0.10$ and $h = 0.15$ respectively.}\label{plot-results-app2}
\end{figure}