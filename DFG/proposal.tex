\documentclass[a4paper,12pt]{article}
\usepackage{amsmath}
\usepackage{amssymb,amsthm,graphicx}
\usepackage{titlesec}
\usepackage{textcomp}
\usepackage{enumitem}
\usepackage{color}
\usepackage{epsfig}
\usepackage{graphics}
\usepackage{pdfpages}
\usepackage{subcaption}
\usepackage[font=small]{caption}
\usepackage[hang,flushmargin]{footmisc} 
\usepackage{float}
\usepackage{rotating,tabularx}
\usepackage{booktabs}
\usepackage[mathscr]{euscript}
\usepackage{natbib}
\usepackage{setspace}
\usepackage{mathrsfs}
\usepackage[left=2.7cm,right=2.7cm,bottom=2.7cm,top=2.7cm]{geometry}
%\parindent0pt

\input{macros}

\setcounter{secnumdepth}{4}

\titleformat{\paragraph}
{\normalfont\normalsize\bfseries}{\theparagraph}{1em}{}
\titlespacing*{\paragraph}
{0pt}{3.25ex plus 1ex minus .2ex}{1.5ex plus .2ex}
\renewcommand{\baselinestretch}{1.2}



\begin{document}


%{Project Description -- Project Proposals}
%\vspace{25pt}
%{\let\newpage\relax\maketitle}


\begin{center}
\LARGE{New Methods and Theory} 

\LARGE{for the Comparison of Nonparametric Curves}
\end{center}
\vspace{25pt}
 


\noindent {\Large \bf A \hspace{0.2cm} General information}


\section{Applicant(s)}

PI \\
date of birth \\
address \\
telephone \\
e-mail 


%\section{List of abbrevations} 



%\section{Summary} 


%The comparison of trend curves is an important topic in many statistical applications. In economics, one may be interested in comparing the trends in the long-term interest rates of different countries. Similarly, one may want to find out whether there are different trends in real GDP growth for different countries. In finance, large amounts of data on a huge number of stocks ara available nowadays. One may want to compare wherther there the volatility trend is different for different stocks. In climatotology, large spatial data sets have been collected which comprise long temperature time series for many different spatial locations. Climatologists are very much interested in analsing the trending behaviour of these time series. In particular, they would like to know how the trending behaviour varies with the location. 


%The main aim of this project is to develop new methods and theory for the comparison of nonparametric trend curves. Classically, time trends are modelled stochastically in econometrics, e.g.\ by a unit root model. Recently, there has been a growing interest in models with a detemrinsitic time trend. An interesting modelling framework considered in ?? among others is as follows: Suppose we observe a number of time series $\mathcal{Y}_i = \{ Y_{it}: 1 \le t \le T \}$ for $1 \le i \le n$. Each time series $\mathcal{Y}_i$ is modelled by the equation
%\begin{equation}\label{model}
%Y_{it} = m_i \Big( \frac{t}{T} \Big) + \beta_i^\top X_{it} + \alpha_i + \varepsilon_{it}
%\end{equation}
%for $1 \le t \le T$, where $m_i$ is a nonparametric trend curve, $X_{it} = (X_{it,1},\ldots,X_{it,d})$ is a $d$-dimensional vector of regressors or controls and $\beta_i$ is the corresponding parameter vector, $\alpha_i$ are so-called fixed effect error terms and $\varepsilon_{it}$ are standard regression errors with $\ex[\varepsilon_{it}] = 0$ for all $t$. 


%Within model \eqref{model}, one may consider several interesting statistical questions. The first one is the following: Are all time trends $m_i$ the same? That is, do all time series in the sample exhibit the same tending behaviour. This question can be approached formally as a testing problem. The null hypothesis is of interest can be formulated as $H_0: m_1 = \ldots = m_n$. [Literature on comparison of trend curves and more generally of regression curves.] 


%%%%%%%%%%%


%The main aim of this project is to develop new methods for the comparison and clustering of nonparametric curves. Depending on the application context, the curves of interest are densities, distribution, quantile or regression functions. We focus attention to the regression context. In particular, we consider a model with nonparametric regression functions which can be interpreted as nonparametric time trend curves. Since Stock and Watson (1988), there has been in particular a large literature in econometrics on testing for common trends. Our project aims to introduce and establish novel methods for the comparison of trend curves which are superior to existing methods in at least two respects: (a) Unlike the great bulk of existing methods, the proposed procedures are free of classical smoothing or bandwidth parameters that are notoriously difficult to select in practice. (b) The methods are much more informative than standard tests. They do not only allow to test whether the curves of interest are different. They also allow It also allows to detect, with a given statistical confidence, which time curves are different and in which regions of the support they differ. Based on our test method, we further construct an algorithm which clusters the observed time series into groups with the same trend.


%%%%%%%%%%%


%Testing for equality of nonparametric curves is a classical theme in econometrics and statistics. Depending on the application context, the curves of interest are densities, distribution, quantile or regression functions. A large number of different tests have been developed over the last few decades. 

%A classical theme in econometrics and statistics is the comparison of nonparametric curves. A number of different statistical methods have been developed to test for equality curves. Depending on the application context, the curves of interest are densities, distribution, quantile or regression functions. Since Stock and Watson (1988), there has been in particular a large literature on testing for the equality of trend curves. In this project, we 

%[Testing for equality of curves] A classical theme in econometrics and statistics is the comparison of nonparametric curves. The comparison is carried out by statistical tests for equality of curves. Most commonly, the curves of interest are densities, distribution and regression functions. The great bulk of tests extisting in the literature proceed in two steps: They first estimate the curves of interest by nonparametric methods and then construct a distance measure between the estimated curves. This distance measure serves as a test statistic. These tests all depend on a smoothing parameter. However, there is no theory available for a proper choice of the bandwidth/smoothing parameter. In particular, the optimal bandwidth for curve fitting cannot be used as optimal bandwidth for the testing problem. 

%A classical way out is to use empirical process theoryx and partial sum processes to get a bandwidth-free test statistic. A more modern way which is related to these partial sum processes are so-called multiscale tests. The idea is as follows: ?? However, multiscale tests for the comparison of nonparametric curves under general conditions are not available to the best of our knoweldge. One aim of the oprpject is to develop such a test for nonparametric regression curves. 

%[Clustering] In classical application, the number of curves to be compared is small. Indeed, much of the classical theory is restricted to tge case that there are two curves to be compared. In modern applications, large data sets are available which comprise information on a large number of curves. For example, there may dasta avaiable on a hundereds of different stocks or households which are characterized by some density or regression function. In this conztext, clasical tests for equality of curves are not an appropriate tool any more: In most aplications, it is very unliely that all individuals are characterized by the same curve. hence, quite likely at least some of the cruves are different. It is very natural to impose a group structure on the curves: One may assume that the curves that not each curve is completely different. There may rather be a small number of different curves, groups ??? Most clustering methods deopend on a number of bandwidths. Bandwidth free methods are very limited. In this project, we further develop a suggestions of ??. 



%\section{Scientific discipline and field of work} 
%
%Applied statistics, mathematical statistics, econometrics.

%\section{Scheduled total duration}

%2 years from ?? to ??.

%\section{Application period} 

%Start: ?? \\
%Finish: ??.


%\section{Summary}


%General topic of the project: Comparison and clustering of nonparametric curves. 

%Depending on the applications, the curves of interest may be densities, distribution, regression or quantile functions. 

%Since Stock and Watson (1988), there has been a large literature on comparing nonparametric trend curves. In the project, we focus attention to nonparametric trend curves, that is, to regression cruves with fixed design points. 

%The project develops and studies new methods for the comparison and clustering of nonparametric curves. Depending on the application, the curves of interest may be densities, distribution, regression or quantile functions. In the project, we focus attention on the case of regression functions as this is the prevalent case in econometrics. The modelling framework can be summarized as follows: We observe $n$ different data sets $\mathcal{D}_i$ for $1 \le i \le n$, where the data of the $i$-th sample $\mathcal{D}_i$ follow a nonparametric regression model with the unknown function $m_i$ and fixed design points. 

%Depending on the application context, the curves of interest may be densities, distibution, quantile or reuression functions among other things. In the econometrics context, most applications presumably involve regression functions. Since Stock and Watson (1988), there is in particular a large literautre in econometrics on testing for common trends. Trend functions can be regarded as regression functions with fixed equidistant design points. In our project, we concentrate on this situation as it is on the one hand interesting for many applications and on the otrher hand a good starting point for extensions.  

%Consider the following situation: Suppose there are $n$ different data sets $\mathcal{D}_i$ available for $1 \le i \le n$. Each data set corresponds to some unknown function $m_i$ which 

%Similar as before, our method does not only allow
%to test whether the null hypothesis is violated. It also allows to detect, with a given
%statistical confidence, which time trends are different and in which time regions they
%2differ from each other. Based on our test method, we further construct an algorithm
%which clusters the observed time series into groups with the same trend.

%method to test for equality of nonparametric curves. Moreover, we use this method to construct a clustering method 

%\section{Combined summary}



\vspace{30pt}

\noindent {\Large \bf B \hspace{0.2cm} Project description}
\setcounter{section}{0}


\section{State of the art and preliminary work}


The comparison of trend curves is an important topic in many statistical applications. Economists, for example, are interested in comparing the trends of long-term interest rates for different countries. Moreover, they may want to assess whether the trends in real GDP growth differ across countries. In finance, massive amounts of data on thousands of stocks are available today. One question of interest is to compare how the volatility of different stocks evolves over time. Finally, in climatotology, large spatial data sets have been collected which comprise long temperature time series for many different locations. Climatologists are very much interested in analyzing the trending behaviour of these time series. In particular, they would like to know how the temperature trend varies across locations. 


The main aim of this project is to develop new methods and theory for the comparison of nonparametric trend curves. Classically, time trends are modelled stochastically in econometrics, e.g.\ by a unit root model [see ??]. Recently, there has been a growing interest in models with deterministic time trends [see ??]. An interesting modelling framework considered in ?? among others is as follows: Suppose we observe a number of time series $\mathcal{Y}_i = \{ Y_{it}: 1 \le t \le T \}$ for $1 \le i \le n$. Each time series $\mathcal{Y}_i$ is modelled by the equation
\begin{equation}\label{model}
Y_{it} = m_i \Big( \frac{t}{T} \Big) + \beta_i^\top X_{it} + \alpha_i + \varepsilon_{it}
\end{equation}
for $1 \le t \le T$, where $m_i$ is a nonparametric trend curve, $X_{it} = (X_{it,1},\ldots,X_{it,d})$ is a $d$-dimensional vector of regressors or controls and $\beta_i$ is the corresponding parameter vector, $\alpha_i$ are so-called fixed effect error terms and $\varepsilon_{it}$ are standard regression errors with $\ex[\varepsilon_{it}] = 0$ for all $t$. Within model \eqref{model}, one may approach several interesting statistical questions.
\vspace{15pt}


\noindent \textit{(a) Testing for equality of nonparametric trend curves. } 
\vspace{10pt} 

 
\noindent The first question is the following: Are all time trends $m_i$ the same? That is, do all time series in the sample exhibit the same trending behaviour? This question can be approached formally by means of a statistical test. The null hypothesis can be formulated as $H_0: m_1 = \ldots = m_n$. 
\begin{itemize}[label=--,leftmargin=0.5cm]
\item \cite{Stock1988} is one of the first papers to compare trend curves in a multiple time series. However, the focus of the author's attention is rather on stochastic trends than deterministic ones. The authors develop two tests for detecting common stochastic trends in a number of time series. They apply these tests to the economic time series, in particularly, the postwar U.S. data on the federal funds rate and the three- and twelve-month treasury bill rates. All three time series on inerest rates appear to share a common stochastic trend.

%Both tests involve the roots of the ordinary least squares coefficient matrix obtained by regressing the series onto its first lag. 
\item \cite{Vogelsang2005} consider a simple linear model
\begin{equation}\label{model-vogelsang}
Y_{it} =\alpha_i + \beta_i t + \varepsilon_{it}, \quad i=1, \ldots, n, \quad t=1, \ldots, T,
\end{equation}
where $\beta_i t$ is a linear trend function, $\alpha_i$ are so-called fixed effect error terms and $\varepsilon_{it}$ are standard regression errors such that a functional central limit theorem is applicable to $\{\varepsilon_{it}\}$. This model can be considered as a special case for our model \eqref{model} with nonparametric time curve $m_i(t)$ being linear in $t$. The authors propose two $F-$tests and a $t$-test to test the null hypothesis 
\begin{equation}\label{hypothesis-vogelsang}
H_0: R\beta = r,
\end{equation}
where $R$ is $q \times n$ known deterministic matrix and $r$ is $q\times 1$ known deterministic vector. They derive an asymptotic theory for these tests and provide relevant critical values. As an empirical application, the authors compare the postwar European time series of gross domestic product (GDP) to the time series of GDP in Italy. They reject the null hypothesis that the rates of growth between Italy and 6 other European countries in the years 1950 to 1992 are the same.

%A key issue is the estimation of the asymptotic covariance matrix, for which we aim to compare three different approaches, amongst which is the familiar heteroskedasticity autocorrelation consistent (HAC) estimator. The other two approaches are new andare basedon extensions of the approach proposedby Kiefer and Vogelsang (2002a). 
\item \cite*{Park2008}, \cite*{ParkHannigKang2009} and \cite*{Park2009} extend the well-known SiZer method for analyzing one time series, which was originally proposed by \cite{ChaudhuriMarron1999}, and advanced as a procedure to analyze time series \cite{Rondonotti2007}. In \cite*{Park2008}, only the model with independent idiosyncratic errors $\{\varepsilon_{it}\}$ is considered, whereas in \cite*{ParkHannigKang2009} and \cite*{Park2009} the errors are allowed to be dependent across $t$. The authors use a regression function estimation to fit a local linear function to obtain a kernel etimate. This kernel estimate depends on a location $x$ and a bandwidth $h$. The proposed SiZer method then uses the color map to display the significance of differences between two regression functions for a range of locations $x$ and locations $h$. This is a useful graphical tool that can indicate the regions where the differences between trend curves should be investigated further. However, this method has its limitations since the comparison should be done only pairwise

%for example seismic recordings of earthquakes and nuclear explosions, gait analysis, temperature precipitation patterns, brain potentials evoked by flashes of light, packet/byte counts in Internet traffic, and so on.
\item \cite*{DegrasWu2012} is a seminal paper on the parallelism between the deterministic trends in multiple time series. The model considered is 
\begin{equation}\label{model-degras}
Y_{it} = m_i \Big( \frac{t}{T} \Big) + \varepsilon_{it}
\end{equation}
for $1 \le t \le T$ and $1 \le n \le N$, where $m_i$ is a nonparametric trend curve and $\varepsilon_{it}$ are standard regression errors with zero mean for all $t$. Furthermore, $\varepsilon_{it}$ are allowed to be weakly dependent in the terms of \cite{Wu2005}. This dependence is non-stationary and it generalizes the stationary assumptions on the error process used previously in the literature. In our proposed project we also intend to follow this model (and this non-stationary error process), further including the fixed effect $\alpha_i$ and the covariates $\{X_{it}\}$.

The authors test the parrallel hypothesis, specifically, $H_0: m_i(u) = c_i +m(u)$ for all $i=1, \ldots, N$ and $u\in[0,1]$. In this setting $c_i$ are considered to be vertical shifts between the reference curve $m(u)$ and the $i$-specific curve $m_i(u)$. In order to do so, the authors first estimate the individual trends $m_i(u) - c_i$ and the common trend $m(u)$ by the means of local linear smoothing procedure and then they develop a test based on the $L_2$-distances between the estimators. They derive the asymptotic theory for the proposed test and decise a  clustering algorithm based on the test statistic. As an illustration of the use of the proposed method, the authors analyze download trends (up to a scale) in the time series that consist of cell phone download activity in different areas in the United States. This is an interesting question for developing region-specific advertising strategies for cell phone companies. 

%For example in longitudinal clinical studies, evaluators are interested in comparing response curves for treatment and control groups. In agriculture, it may be relevant to compare at different spatial locations the relationship between yield per plant and plant density. In biology, assessing parallelism between sets of dose-response data allows to determine if the biological response to two substances is similar or if two different biological environments give similar dose-response curves to the same substance. Another interesting application of comparing trends in cell phone activity pertains to the allocation of bandwidth in phone networks.
\item \cite{Sun2011} considers the same model as in \eqref{model-vogelsang} but focuses on the estimation of the long run variance and its influence on the asymptotic behavior of the OLS esimator of the coefficient. The authors estimate the long run variance matrix by a series type estimator with $K$ basis functions. As in \cite*{Vogelsang2005}, the authors test the null hypothesis \eqref{hypothesis-vogelsang} but employ Wald statistic instead of $F$-test or $t$-test. They prove that the asymptotic distribution of the Wald statistic converges to a standard distribution when $K$ is fixed and when $K$ is growing. The authors also provide an algorithm to select $K$ developed such that it minimizes the type II error controlling for the type I error.

%It is shown that critical values from the fixed-K asymptotics are second order correct under the large-K asymptotics. The new test therefore combines the advantages of the nonstandard test and the standard Wald test while avoiding their main disadvantages (power loss and size distortion, respectively).
\item \cite{Xu2012} expands the framework in \cite*{Vogelsang2005} by considering the same model \eqref{model-vogelsang} but allowing the errors $\varepsilon_{it}$ to follow a semi-parametric vector autoregressive (VAR) process with nonstationary volatility. In this setting the conventional $F$-tests and the $t$-test proposed in \cite*{Vogelsang2005} are generally non-pivotal in the limit, hence, the authors propose robust tests to overcome this issue. Moreover, they propose a bootstrap procedure to improve the perfomance of these test in small samples.

%involving the unknown timevarying volatility function in the limit. This can be explained by either of the two facts. First, under nonstationary volatility the nonrobust standard errors incorrectly estimate the asymptotic variances of the trend coefficients. This is analogous to the failure of the traditional t-test in the presence of heteroskedasticity. Second, the maintained assumption in VF that a standard invariance principle holds for model innovations is violated under nonstationary volatility. A class of robust tests is then suggested. Although the robust tests proposed are asymptotically pivotal under a quite general type of nonstationary volatility, they may suffer from large size distortions in small samples. We then propose for practical use two types of two-step residual-based bootstrap procedures, i.i.d. bootstrap and wild bootstrap, that can be applied to the robust tests.
\item \cite*{Zhang2012}.

%This paper develops a test for common trends in a semi-parametric panel data model of the
%form that can be correlated with Xit, and its are idiosyncratic errors. The trend functions fi(t/T )
%that appear in (1.1) provide for idiosyncratic trends for each individual i. For simplicity, we will
%assume that (i)  satisfies certain martingale difference conditions along the time dimension
%but may be correlated across individuals, and (ii)  are independent of {Xit}. Note that fi and
%i are not identified in (1.1) without further restrictions.
%Model (1.1) covers and extends some existing models. First, when fi 0 for all i, (1.1)
%becomes the traditional panel data model with fixed effects. Second, if n = 1, then model (1.1)
%reduces to the model discussed in Gao and Hawthorne (2006). Third, when fi = f for some
%unknown smooth function f and all i, (1.1) becomes the semi-parametric trending panel data
%model of CGL (2011).
%The main objective of this paper is to construct a non-parametric test for common trends.
%Under the null hypothesis of common trends: fi = f for all i in (1.1), we can pool the
%observations from both cross-section and time dimensions to estimate both the finite dimensional
%parameter () and the infinite dimensional parameter (f ) under the single identification
%restriction the estimate of uit based on the pooled regression. The residuals {uit} should not contain any
%useful trending information in the data. This motivates us to construct a residual-based test for the
%null hypothesis of common trends. To be concrete, we will propose a test for common trends by
%averaging the n measures of non-parametric goodness-of-fit (R2) from the non-parametric time
%series regressions of uit on the time trend for each cross-sectional unit i. Such non-parametric
%R2 should tend to zero under the null hypothesis of common trends and diverge from zero
%otherwise. We show that after being properly centred and scaled, the average non-parametric
%R2 is asymptotically normally distributed under the null hypothesis of common trends and a
%sequence of Pitman local alternatives. We also establish the consistency of the test and propose
%a bootstrap method to obtain the bootstrap P-values.1
%To proceed, it is worth mentioning that (1.1) complements the model of Atak et al. (2011)
%who allow for heterogeneous slopes but a single non-parametric common trend across crosssections. As mentioned in the concluding remarks, it is also possible to allow the slope
%coefficients in (1.1) to vary across individuals and consider a joint test for the homogeneity of
%the slope coefficients and trend components. But this is beyond the scope of this paper

\item \cite{Hidalgo2014}.

\end{itemize}


Most tests of the hypothesis $H_0: m_1 = \ldots = m_n$ existing in the literature proceed in two steps: They first estimate the curves of interest by nonparametric methods and then construct a distance measure between the estimated curves which serves as a test statistic. By construction, these tests depend on one or several smoothing parameters which are needed to estimate the curves $m_i$. However, there is no theory available for a proper choice of the bandwidth/smoothing parameter. In particular, the optimal (MSE minimizing) bandwidth used for curve fitting is usually not optimal for testing. A classical way to get a bandwidth-free test statistic is to use empirical process theory and partial sum processes [cp.\ \cite{Hidalgo2014}]. A more modern way which is related to these partial sum processes are so-called multiscale tests. The idea is as follows: ?? 


Multiscale tests for the comparison of nonparametric curves under general conditions are not available to the best of our knowledge. One aim of the project is to develop such a test for nonparametric regression curves. Multiscale tests do not only have the advantage of being bandwidth-free. They also are much more informative compared to other tests. They do not only allow to test whether the curves $m_i$ are all the same or not; they also allow to say, with a pre-specified statistical confidence, which curves are different and in which regions they differ.  
\vspace{15pt}


\noindent \textit{(b) Clustering of nonparametric trend curves. } 
\vspace{10pt} 


%Testing the equality of nonparametric curves is a classical theme in econometrics and statistics. In the simplest setting, two data sets $\mathcal{D}_i = \{ (Y_{it},X_{it}): 1 \le t \le T \}$ for $i=1,2$ are observed, where $T$ denotes the sample size of each data set. The data are supposed to come from the model 
%\begin{equation}\label{model-1}
%Y_{it} = m_i(X_{it}) + \varepsilon_{it}, 
%\end{equation}
%where $m_i$ denotes the unknown (nonparametric) regression function for each data set and $\varepsilon_{it}$ is the error term. The aim is to construct a statistical test for the hypothesis $H_0: m_1 = m_2$ that the two regression curves are equal. A number of tests have been proposed for this problem. ??

%(1) A classical theme in econometrics and statistics is the comparison of nonparametric curves. In many applications, the curves of interest can be interpreted as (determinstic or stochastic) trends. Starting with Stock and Watson (1988), there has been a growing literature in econometrics on testing for common trends [good summary in the introduction of Zhang, Su, Phillips (2012)): 
%\begin{itemize}[label=--,leftmargin=0.5cm]
%\item Stock \& Watson (1988). Testing for common trends.
%\item Vogelsang \& Franses (2005). Testing for common deterministic trend slopes.
%\item Park, Vaughan, Hannig \& Kang (2009). SiZer analysis for the comparison of time series.
%\item Sun (2011). Robust trend inference with series variance estimator and testing-optimal smoothing parameter.
%\item Xu (2011). Robustifying multivariate trend tests to nonstationary volatility.
%\item Zhang, Su \& Phillips (2012). Testing for common trends in semi-parametric panel data models with fixed effects.
%\end{itemize}

\noindent When the number of curves is large, classical tests for the comparison of nonparametric curves are not fully appropriate as a statistical tool. The issue is the following: In most applications where the number of curves is large, one can expect that not all curves are exactly the same. Hence, a test of the null that all curves are the same is quite uninformative. Most frequently, the hypothesis will be rejected. A more interesting question is the following: Are there groups of curves that are the same? This question leads to the problem of curve clustering. Clustering of coefficient or functions in panel data models is a relative young emerging field in econometrics: 
\begin{itemize}[label=--,leftmargin=0.5cm]
\item \cite{Bonhomme2015}. Grouped patterns of heterogeneity in panel data.
\item \cite*{Su2016}. Identifying latent structures in panel data.
\item \cite{Su2018}. Identifying latent grouped patterns in panel data models with
interactive fixed effects.
\item \cite{Wang2018}. Homogeneity pursuit in panel data models: theory and application.
\end{itemize}
In the statistics literature, there is also a literature on curve clustering (functional and longitudinal data): 
\begin{itemize}[label=--,leftmargin=0.5cm]
\item \cite*{Abraham2003}. Unsupervised curve clustering using B-splines.
\item \cite{James2003}. Clustering for sparsely sampled functional data.
\item \cite*{Tarpey2003}. Clustering functional data.
\item \cite*{Ray2006}. Functional clustering by Bayesian wavelet methods.
\item \cite{Chiou2007}. Functional clustering and identifying substructures of longitudinal data.
\item \cite*{DegrasWu2012}. Testing for parallelism among trends in multiple time series.
\end{itemize}
Most of the clustering procedures in the literature depend on a number of smoothing parameters. Multiscale approaches do not. 



\subsection{Project-related publications}

\subsubsection{Articles published by outlets with scientific quality assurance, book publications, and works accepted for publication but not yet published}

\subsubsection{Other publications}

\section{Objectives and work programme}

\subsection{Anticipated total duration of the project}

2 years from 01.10.2019 to 30.09.2021



\subsection{Objectives}


The main aim of the project is to develop new methods and theory for the comparison and clustering of nonparametric curves. We intend to consider the following model framework: Suppose we observe a number of time series $\mathcal{Y}_i = \{ Y_{it}: 1 \le t \le T \}$ for $1 \le i \le n$. Each time series $\mathcal{Y}_i$ is modelled by the equation
\begin{equation}\label{model-objectives}
Y_{it} = m_i \Big( \frac{t}{T} \Big) + \beta_i^\top X_{it} + \alpha_i + \varepsilon_{it}
\end{equation}
for $1 \le t \le T$, where $m_i$ is a nonparametric trend curve, $X_{it} = (X_{it,1},\ldots,X_{it,d})$ is a $d$-dimensional vector of regressors or controls, $\alpha_i$ are so-called fixed effect error terms and $\varepsilon_{it}$ are standard regression errors with $\ex[\varepsilon_{it}] = 0$ for all $t$. As usual in nonparametric regression, we let $m_i$ depend on rescaled time $t/T$ rather than real time $t$; compare ??, ?? and ?? among many others for the use of the rescaled time argument. For simplicity, the controls $X_{it}$ are assumed to enter the model equation linearly with $\beta_i$ being the corresponding parameter vector. However, it is possible to extend the model to allow for nonlinear parametric and even nonparametric specifications of $X_{it}$. [Conditions on the fixed effects and the error terms.] 


The first main contribution of the project is to contruct a novel multiscale test for the comparison of the trend curves $m_i$ ($1 \le i \le n$). Compared to existing methods, the approach has the following main advantages: 
\begin{enumerate}[label=(\arabic*),leftmargin=0.75cm]
\item 
\item 
\end{enumerate}
To the best of our knoweledge, there is no other multiscale method available in the literature. The only exception is ?? who have developed theory for the case $n=2$. However, the theory is developed under severe restrictions: ??.   
We do not only aim to develop methodology but also derive a complete asymptotic theory for the proposed multiscale test. In particular, we will derive the limit distribution and analyse the behaviour under (local) alternatives. 


The second main contribution is to develop a clustering approach which is based on the multiscale test from the first main part of the project. The only multiscale clustering method available in the literature is \cite*{VogtLinton2018}. They consider a very general nonparametric regression model but only derive consistency results for the clustering method. We consider a somewhat simpler model but will derive a complete distribution theory for the clustering method (which in particular allows to make not only converge statements but also confidence statements about the estimated groups and their number). 


Model \eqref{model-objectives} and the proposed testing/clustering method are useful in a number of application contexts which we aim to explore. We here give some examples: 

%In the finance literature, VF’s common trend tests were used by Carrieri et al. (2004) to explain the dynamics in the gains from sectoral versus cross-country diversification of equity markets, and by Eun and Lee (2006) to study risk-return convergence of several developed stock markets. Other applications of VF’s tests to environmental data and geodetic data can be found in Fomby and Vogelsang (2003), Vogelsang and Franses (2005b) and Bacigál (2005).
\begin{example}
Short-term risk-free interest rates are one of the main topics of interest in the financial markets. For example, it is a key component of the capital asset pricing model, which describes the relationship between risk and return. Furthermore, the risk-free rate is also a required input in financial calculations regarding the pricing of bonds. There is an evergrowing amount of literature on the dynamics of interest rate. US Treasury bills are the real-world investment that serve as the proxy for these rates. \cite{Park2009} analyze the yields of the 3-month, 6-month, and 12-month Treasury bills in the context of comparing nonparametric curves. The authors assume that the yields come from the following model:
\begin{equation}\label{model-park}
Y_{it} = m_i(t) + \sigma_i \varepsilon_{it}, \quad i=1,\ldots, n, \quad t=1,\ldots,T,
\end{equation}
which is a simplification of our model \eqref{model-objectives}. \cite{Park2009} apply Si{Z}er method to the data and come to the conclusion that the underlying structure for different time periods is almost identical. They could not find any significant difference between any pair of the time periods, which concides with the results from applying other methods, see, for example, \cite{Fan2008}.
\end{example}

\begin{example}
Another example of comparison of time series with nonparametric trend functions described in \cite{Park2009} involves the long-term rates for US, Canada, and Japan from January 1980 to December 2000. The data is assumed to follow the same model \eqref{model-park}. The authors perform pairwise comparison of the curves as well as comparison of the three time series at the same time using the proposed Si{Z}er method. In both cases their method was able to detect significant differences nd indicate ``suspicious'' regions. However, since Si{Z}er is a graphical device that is mainly designed for data exploration rather than for rigorous statistical inference, they do not make simultaneous confidence statements with a predetermined confidence level about the regions where these differences were most probable to occur. Our proposed multiscale method, in contrast, is a rigorous level-$\alpha$-test of the hypothesis $H_0$ which is aimed specifically at that.
%the long-term interest rates for the US and Canada moved quite closely together from approximately 1993 to 1995, despite different business cycle positions at those times. We also can confirm in the SiZer map the events of the fall of the Canadian rates to just below the US rates for the first time in over a decade around 1996.

%we can see that in the period from 1982 to mid 1984 the US rates rose as the Japanese rates were falling, believed by the authors to be caused in part by the effects of US fiscal expansion in raising the demand for domestic savings relative to its supply indicating this early 1980s time period. we can see significant divergences in the interest rates in the late 1980s as US rates begin to fall back, rates in Canada and Japan are increasing. the larger values of Canada and Japan cause a significant negative difference. We can see this short-term similarity between Canada and Japan, however, the graph is clearly dominated by the more rapid descent of the Canadian rates through the overall decrease of both countries.

%It would also be interesting to compare three yields of three countries at the same time, as in Examples 1 and 2, respectively. To save space we only report the result of Example 2 for multiple comparison. We can see that in Fig. 9, there are differences that occur within each SiZer map, denoting that there are present. We have seen in Fig. 8 that there existed pairwise differences between all of the countries. The presence of these differences are also correctly detected when we compare each set of residuals from each country's individual estimated function to the residuals from the overall estimation.
\end{example}

\begin{example}
Economic growth has been a key topic in marcoeconomics over many decades. Economists are very much interested in the question whether gross domestic product (GDP) growth  has been faster in some countries than in others. One of the ways to model the source of economic growth is to incorporate a nonparametric deterministic time trend in the model. For example, \cite{Zhang2012} consider such a model for the OECD economic growth data. Specifically, they investigate the following model for growth rates:
\begin{equation}\label{model-zhang}
\Delta \ln GDP_{it} = \beta_1 \Delta \log L_{it} +\beta_2 \Delta \log K_{it} +\beta_3 \Delta \log H_{it} +f_i(t/T) +\alpha_i + \varepsilon_{it},
\end{equation}
where $i = 1,\ldots, n$, $t = 1, \ldots, T = 140$, $GDP$ is gross domestic product, $K$ is capital stock, $L$ is labour input, $H$ is human capital, $\alpha_i$ is a fixed effect, $f_i(\cdot)$ is an unknown smooth time trend furnction and $\varepsilon_{it}$ are idiosyncratic errors. The errors are allowed to be dependent cross-sectionally, but not serially over $t$. The data comes from $n = 16$ OECD countries.

\cite{Zhang2012} estimate the common component of time trends which appears to be significantly different from zero over a wide range its support. Moreover, they test the null hypothesis that there are no significant differences in the time trends for the 16 OECD countries. Based on the bootstrap $p$-values the authors are able to reject the null hypothesis of all the trends being equal at the 10\% confidence level. Hence, it can be interesting to be able to further cluster the OECD countries based on their economic growth rates.
\end{example}

\begin{example}
The issue of global warming has been a vital topic for many scientists over the last few decades. Since the late 1970, different models that describe the global temperature have been published. In the current literature it is common to assume that the temperate time series (global as well as local) follow a model that can be decomposed into a deterministic trend component and a noise component, see, for example, \cite{Ghil1991} and \cite{Mudelsee2018}. In order to estimate and attribute the trends in climate variables, a variety of econometric methods have been employed, starting from the simple linear (\cite{Yue2013}) and quadratic regression (??) to the empirical mode decompoistion (\cite{Wu2011}), spectrum analysis (\cite{Ghil1991}) and semi- and fully non-parametric methods (\cite{Gao2006}). Parametric and change points methods are mostly suited to quantify the magnitude of the warming trend or to determine the change points, whereas nonparametric methods are best designed to describe the trend over the full time interval without imposing any additional structure on it. However, most of these papers apply nonparametric methods to analyze only one time series or the authors assume that the trend function is common for different time series (\cite{Atak2011}). To our knowledge, only a few papers regarding the comparison of warming trends in different cities or countries have been published (\cite{Zhang2012}). 

%\cite{Atak2011} propose the following semiparametric panel model for unbalanced data to describe the trend in UK regional temperatures:
%\begin{equation}\label{model-atak}
%y_{it} = \alpha_i + \beta_i^\prime D_t + \gamma_i^\prime X_{it} + g(t/T) + \varepsilon_{it},
%\end{equation}
%where $y_{it}$ are the monthly mean temperature at a station $i, i =1, \ldots, n$ in month $t, t=t_i, \ldots, T$, $D_t$ is a vector of seasonal dummy variables, $X_{it}$ are a vector of observed covariates, $\alpha_i$ is a fixed effect for station $i$, $g(\cdot)$ is an unknown single common trend and $\varepsilon_{it}$ are idiosyncratic errors.

\cite{Zhang2012} propose the following semiparametric panel model for unbalanced data to describe the trend in UK regional temperatures:
\begin{equation}\label{model-atak}
y_{it} =\beta_i^{T}D_t + m_i(t/T) + \alpha_i + \varepsilon_{it},\quad i =1, \ldots, n, \quad t=1, \ldots, T
\end{equation}
where $y_{it}$ are the monthly mean maximum temperature, monthly mean minimum temperature or total rainfall in millimeters at a station $i$ in month $t$, $D_t$ is a $11$-dimensional vector of monthly dummy variables, $\alpha_i$ is the fixed effect for station $i$, $m_i(\cdot)$ is an unknown trend function and $\varepsilon_{it}$ are idiosyncratic errors. The dataset used is the balanced panel data set for $n=26$ stations in UK for $T=382$ months from October 1978 to July 2010. This model is a special case of our proposed model \eqref{model-objectives} with dummy variables as covariates.

\cite{Zhang2012} are interested in testing the null hypothesis $m_i = m$ for all $i =1, 2, \ldots, n$. In order to do this, they apply a non-parametric $R^2$-based test for common trends that was developed in their paper. Based on the obtained $p$-values, they reject the null hypothesis of common trend at $5\%$ level for the monthly mean maximum temperature and the monthly mean minimum temperature. However,  they do not reject the null hypothesis for the total rainfall eve at the significance level of $10\%$. As before, it would be interesting to further cluster the UK stations based on the common trend in order to be able to detect the causes of this warming trend. Moreover, it can also be of particular interest to see in which time regions the trends are significantly different from each other.

%Over the past decade, substantial efforts have gone into establishing reliable and accurate records of surface air temperatures for periods of a century or more. The Intergovernmental Panel on Climate Change (IPCC) Report 10 provides an excellent review of remaining problems. We have chosen for the present analysis the time series of annually-averaged temperatures from 1854 to 1988 produced by the Climate Research Unit (CRU) of the University of East Anglia, and verified the results against the IPCC consensus time series (1856-1989). Only the annual means for the Northern Hemisphere (NH), Southern Hemisphere (SH) and the entire globe were used here.
%An ever-growing body of evidence regarding observed changes in the climate system has been gathered over the last three decades, and large modeling efforts have been carried to explore how climate may evolve during the present century. The impacts from both observed weather and climate endured during the twentieth century and the magnitude of the potential future impacts of climate change have made this phenomenon of high interest for the policy-makers and the society at large. Two fundamental questions arise for understanding the nature of this problem and the appropriate strategies to address it: Is there a long-term warming signal in the observed climate, or is it the product of natural variability alone? If so, how much of this warming signal can be attributed to anthropogenic activities? As discussed in this review, these questions are intrinsically related to the study of the time-series properties of climate and radiative forcing variables and of the existence of common features such as secular co-movements. This paper presents a brief summary of how detection and attribution studies have evolved in the climate change literature and an overview of the time-series and econometric methods that have been applied for these purposes.
%Significant advances have been made in documenting how global and hemispheric temperatures have evolved and in learning about the causes of these changes. On the one hand, large efforts have been devoted to investigate the time series properties of temperature and radiative forcing variables \cite{Gay-Garcia2009}; \cite{Kaufmann2006}; \cite{Mills2013}; \cite{Tol1993}.
%In addition,, including features such as breaks and nonlinearities \cite{Estrada2013}; \cite{Gallagher2013}; \cite{Harvey2002}; \cite{Karl2000}; \cite{Pretis2015}; \cite{Reeves2007}; \cite{Seidel2004}; \cite{Stocker2013}; Tom´e and Miranda, 2004). Multivariate models of temperature and radiative forcing series provide strong evidence for a common secular trend between these variables, and help to evaluate the relative importance of its natural and anthropogenic drivers (Estrada, Perron and Mart´ınez-L´opez, 2013; Estrada, Perron, Gay-Garc´ıa and Mart´ınez-L´opez, 2013; Kaufmann et al., 2006; Tol and Vos, 1998). The methodological contributions of the econometrics literature to this field have been notable; e.g., Dickey and Fuller (1979), Engle and Granger (1987), Johansen (1991), Perron (1989, 1997), Bierens (2000), Ng and Perron (2001), Kim and Perron (2009), Perron and Yabu (2009), among many others, see Estrada and Perron (2014) for a review. Regardless of the differences in assumptions and methods (statisticalor physical), there is a general consensus about the existence of a common secular trend between temperatures and radiative forcing variables.
\end{example}





%The main purpose of the research project is to propose a new multiscale testing and inference approach for the model which consists of multiple time series with time series error structure and in the presence of generated regressors. 

%When several time series $\mathcal{Y}_i = \{ Y_{it}: 1 \le t \le T \}$ are observed for $1 \le i \le n$, we model each time series $\mathcal{Y}_i$ by the equation
%\begin{equation}\label{model2-intro}
%Y_{it} = m_i \Big( \frac{t}{T} \Big) + \alpha_i + \varepsilon_{it}
%\end{equation}
%for $1 \le t \le T$, where $m_i$ is a nonparametric time trend, $\alpha_i$ is a (random or deterministic) intercept and $\varepsilon_{it}$ are time series errors with $\ex[\varepsilon_{it}] = 0$ for all $t$.

%An important question in many applications is whether the time trends $m_i$ are the same for all $i$. When some of the trends are different, there may still be groups of time series with the same trend. In this case, it is often of interest to estimate the unknown groups from the data. In addition, when two trends $m_i$ and $m_j$ are not the same, it may also be relevant to know in which time regions they differ from each other. In Section \ref{sec-test-equality}, we construct statistical methods to approach these questions. In particular, we develop a test of the hypothesis that all time trends in model \eqref{model2-intro} are the same, that is, $m_1 = m_2 = \ldots = m_n$. Similar as before, our method does not only allow to test whether the null hypothesis is violated. It also allows to detect, with a given statistical confidence, which time trends are different and in which time regions they differ from each other. Based on our test method, we further construct an algorithm which clusters the observed time series into groups with the same trend. 



\subsection{Work programme incl. proposed research methods}
All phases of the research will be conducted in close collaboration with the partners in Bonn.
\begin{center}
\begin{tabular}{ c c c c}
{\bf Milestone} & {\bf 2019 }&{\bf 2020}&{\bf 2021}\\
&Month& Month& Month\\
Multiscale inference for fixed number of time series &10-12& 1-9&\\
Multiscale inference for growing number of time series &&10-12 &1-9
\end{tabular}
\end{center}

\subsection{Data handling}
%[Text]

\subsection{Other information}
Please use this section for any additional information you feel is relevant which has not been provided elsewhere.

[Text]

%\subsection{Descriptions of proposed investigations involving experiments on humans, human materials or animals as well as dual use research of concern}

%[Text]

%\subsection{Information on scientific and financial involvement of international cooperation partners}

%[Text]

\section{Bibliography}

\bibliographystyle{ims}
{\small
\setlength{\bibsep}{0.55em}
\bibliography{bibliography}}


\section{Requested modules/funds}
Explain each item for each applicant (stating last name, first name).

\subsection{Basic Module}

\subsubsection{Funding for Staff}
\begin{center}
\begin{tabular}{ c c c c c}
Nr. &Position & 2019 &2020&2021\\
1 &Research staff U. Bonn (EGr. 13 TV-L 75 \%) &11.869 \texteuro &47.475 \texteuro &35.606 \texteuro \\
2 &Student Assistant Bonn &2.700 \texteuro& 10.800 \texteuro& 8.100\texteuro\\
&Required Amount & 14.569\texteuro & 58.275\texteuro& 43.706\texteuro
\end{tabular}
\end{center}

{\bf Job description of staff payed from auxiliary support for the funding period requested }

\begin{enumerate}
	\item Marina Khismatullina already possesses considerable experience in the study of nonparametric models with time series error. Moreover, she is a co-author of the paper ``Multiscale Inference and Long-Run Variance Estimtor in Nonparametric Regression with Time Series Friends'' by Khismatullina and Vogt, which is currently submitted to JRSSB. She will be capable to develop computational software taylored to assess the empirical performance of the proposed multiscale test.
	\item At the onset of the project a student assistent position should be available in order to
support stuff with exploratory data analysis, data mining and organisational issues. The
prerequisities are strong analytical and programming skills.
\end{enumerate}

\subsubsection{Direct Project Costs}

[Text]

\paragraph{Equipment up to Euro 10,000, Software and Consumables}

[Text]

\paragraph{Travel Expenses}

[Text]

\paragraph{Visiting Researchers (excluding Mercator Fellows)}

[Text]

\paragraph{Expenses for Laboratory Animals}

[Text]

\paragraph{Other Costs}

[Text]

\paragraph{Project-related publication expenses}

[Text]


%\subsubsection{Instrumentation}

%\paragraph{Equipment exceeding Euro 10,000}

%[Text]

%\paragraph{Major Instrumentation exceeding Euro 50,000}

%[Text]

%\subsection{Module Temporary Position for Principal Investigator}

%[Text]

%\subsection{Module Replacement Funding}

%[Text] 

%\subsection{Module Temporary Clinician Substitute}

%[Text]

%\subsection{Module Mercator Fellows}

%[Text]

%\subsection{Module Workshop Funding}

%[Text]

%\subsection{Module Public Relations Funding}

%[Text]



\section{Project requirements}

\subsection{Employment status information}
 For each applicant, state the last name, first name, and employment status (including duration of contract and funding body, if on a fixed-term contract).

[Text]

\subsection{First-time proposal data}
Only if applicable: Last name, first name of first-time applicant

[Text]
\subsection{Composition of the project group}
List only those individuals who will work on the project but will not be paid out of the project funds. State each person’s name, academic title, employment status, and type of funding.

[Text]

\subsection{Cooperation with other researchers}

\subsubsection{Researchers with whom you have agreed to cooperate on this project}

[Text]

\subsubsection{Researchers with whom you have collaborated scientifically within the past three years}

[Text]

\subsection{Scientific equipment}
The University of Bonn has a sufficient infrastructure in hard- and software. Personal computers are available and can be used within the project. Equipment like printer, fax and copier can be used as well.

%\subsection{Project-relevant cooperation with commercial enterprises}
%If applicable, please note the EU guidelines on state aid or contact your research institution in this regard.

%[Text]

%\subsection{Project-relevant participation in commercial enterprises}
%Information on connections between the project and the production branch of the enterprise

%[Text]



\section{Additional information}
If applicable, please list proposals requesting major instrumentation and/or those previously submitted to a third party here.

[Text]

\end{document}
