\documentclass[a4paper,12pt]{article}
\usepackage{amsmath}
\usepackage{amssymb,amsthm,graphicx}
\usepackage{enumitem}
\usepackage{color}
\usepackage{epsfig}
\usepackage{graphics}
\usepackage[font=small]{caption}
\usepackage[hang,flushmargin]{footmisc} 
\usepackage{float}
\usepackage{booktabs}
\usepackage[mathscr]{euscript}
\usepackage{natbib}
\usepackage{setspace}
\usepackage{mathrsfs}
\usepackage[left=2.8cm,right=2.8cm,bottom=2.8cm,top=2.8cm]{geometry}
\parindent0pt 

\input{macros}
\renewcommand{\baselinestretch}{1.2}
\numberwithin{equation}{section}
\allowdisplaybreaks[1]




\begin{document}



\begin{center}
{\LARGE \textbf{Multiscale Inference for}} \\[0.35cm]
{\LARGE \textbf{Nonparametric Time Trends}}
\end{center}



\section{The model}


The model setting for the test problems considered in Sections \ref{sec-method} and \ref{sec-test-shape} is as follows: We observe a time series $\{Y_t: 1 \le t \le T \}$ of length $T$ which satisfies the model equation 
\begin{equation}\label{model1}
Y_t = m \Big( \frac{t}{T} \Big) + \varepsilon_t 
\end{equation}
for $1 \le t \le T$. Here, $m$ is an unknown nonparametric regression function defined on~$[0,1]$ and $\{ \varepsilon_t: 1 \le t \le T \}$ is a zero-mean stationary error process. For simplicity, we restrict attention to equidistant design points $x_t = t/T$. However, our methods and theory can also be carried over to non-equidistant designs. The stationary error process $\{\varepsilon_t\}$ is assumed to have the following properties: 
\begin{enumerate}[label=(C\arabic*),leftmargin=1.05cm]

\item \label{C-err1} The variables $\varepsilon_t$ allow for the representation $\varepsilon_t = G(\ldots,e_{t-1},e_t,e_{t+1},\ldots)$, where $e_t$ are i.i.d.\ random variables and $G: \reals^\integers \rightarrow \reals$ is a measurable function. 

\item \label{C-err2} It holds that $\| \varepsilon_t \|_q < \infty$ for some $q > 4$, where $\| \varepsilon_t \|_q = (\ex|\varepsilon_t|^q)^{1/q}$. 

\end{enumerate}
Following \cite{Wu2005}, we impose conditions on the dependence structure of the error process $\{\varepsilon_t\}$ in terms of the physical dependence measure $d_{t,q} = \| \varepsilon_t - \varepsilon_t^\circ \|_q$, where $\varepsilon_t^\circ = G(\ldots,e_1,e_0^\prime,e_1,\ldots,e_{t-1},e_t)$ with $\{e_t^\prime\}$ being an i.i.d.\ copy of $\{e_t\}$. In particular, we assume the following: 
\begin{enumerate}[label=(C\arabic*),leftmargin=1.05cm]
\setcounter{enumi}{2}

\item \label{C-err3} It holds that 
\[ \sum_{t=1}^\infty t \| \varepsilon_t - \varepsilon_t^\circ \|_q < \infty. \]

\end{enumerate}
The conditions \ref{C-err1}--\ref{C-err3} are fulfilled by a wide range of stationary processes $\{\varepsilon_t\}$. As a first example, consider linear processes of the form $\varepsilon_t = \sum\nolimits_{i=0}^{\infty} c_i e_{t-i}$, where $c_i$ are absolutely summable coefficients and $e_t$ are i.i.d.\ innovations with $\ex[e_t] = 0$ and $\| e_t\|_q < \infty$. Obviously, \ref{C-err1} and \ref{C-err2} are fulfilled in this case. Moreover, if $|c_i| = O(\rho^i)$ for some $\rho \in (0,1)$, then \ref{C-err3} is easily seen to be satisfied as well. As a special case, let $\{\varepsilon_t\}$ be an ARMA process of the form $\varepsilon_t + \sum\nolimits_{i=1}^p a_i \varepsilon_{t-i} = e_t + \sum\nolimits_{j=1}^r b_j e_{t-j}$, where $a_1,\ldots,a_p$ and $b_1,\ldots,b_r$ are real-valued parameters and the complex polynomials $A(z) = 1 + \sum\nolimits_{j=1}^p a_jz^j$ and $B(z) = 1 + \sum\nolimits_{j=1}^r b_jz^j$ do not have any roots in common. If $A(z)$ does not have any roots inside the unit disc, then the ARMA process is stationary and causal. Specifically, it has the representation $\varepsilon_t = \sum\nolimits_{i=0}^{\infty} c_i e_{t-i}$ with $|c_i| = O(\rho^i)$ for some $\rho \in (0,1)$, implying that \ref{C-err1}--\ref{C-err3} are fulfilled. As shown in \cite{WuShao2004}, the condition \ref{C-err3} (as well as the other two conditions) is not only fulfilled for linear time series processes but also for a variety of non-linear processes. 


The model setting for the test problem analyzed in Section \ref{sec-test-equality} is closely related to the setting discussed above. The main difference is that we observe several rather than only one time series. In particular, we observe time series $\mathcal{Y}_i = \{Y_{it}: 1 \le t \le T \}$ of length~$T$ for $1 \le i \le N$. Each time series $\mathcal{Y}_i$ satisfies the regression equation \begin{equation}\label{model2}
Y_{it} = m_i \Big( \frac{t}{T} \Big) + \alpha_i + \varepsilon_{it} 
\end{equation}
for $1 \le t \le T$, where $m_i$ is an unknown nonparametric function defined on $[0,1]$, $\alpha_i$ is a (deterministic or random) intercept term and $\mathcal{E}_i = \{ \varepsilon_{it}: 1 \le t \le T \}$ is a zero-mean stationary error process. For identification purposes we normalize the functions $m_i$ such that $\int_0^1 m_i(u) du = 1$ for all $1 \le i \le N$. The conditions on the error processes $\mathcal{E}_i$ can be summarized as follows: The processes $\mathcal{E}_i$ are independent across $i$ and each process $\mathcal{E}_i$ satisfies the conditions \ref{C-err1}--\ref{C-err3}. We thus work with essentially the same error structure as in our analysis in Sections \ref{sec-method} and \ref{sec-test-shape}.



\section{The multiscale test procedure}\label{sec-method}


In this section, we introduce our multiscale test method and the underlying theory for the simple hypothesis $H_0: m = 0$ in the model \eqref{model1}. Both the method and the theory for this simple case can be easily adapted to more interesting test problems as we will see in Sections \ref{sec-test-shape} and \ref{sec-test-equality}. 
%The discussion can be regarded as providing a blueprint of our multiscale methods and the underlying theory, which is ready to adapt to more advanced test problems. 


\subsection{Construction of the test statistic}\label{subsec-method-stat}


To construct a multiscale test statistic for the hypothesis $H_0: m = 0$ in the model \eqref{model1}, we consider the kernel averages
\begin{equation}\label{kernel-ave}
\widehat{\psi}_T(u,h) = \sum\limits_{t=1}^T w_{t,T}(u,h) Y_t, 
\end{equation}
where $w_{t,T}(u,h)$ is a kernel weight with $u \in [0,1]$ and $h$ being the bandwidth parameter. We in particular set 
\[ w_{t,T}(u,h) = \frac{1}{\|K\|_{u,h,T}} K\Big( \frac{u - t/T}{h} \Big) \, \quad \text{with} \quad \|K\|_{u,h,T} = \Big\{\sum\limits_{t=1}^T  K^2\Big( \frac{u - t/T}{h} \Big)\Big\}^{1/2}, \]
where $K$ is a non-negative kernel function which is symmetric about zero, integrates to one and has compact support $[-1,1]$. The kernel average $\widehat{\psi}_T(u,h)$ is a local average of the observations $Y_1,\ldots,Y_T$ which gives positive weight only to data points $Y_t$ with $t/T \in [u-h,u+h]$. Hence, only observations $Y_t$ with $t/T$ close to the location $u$ are taken into account, the amount of localization being determined by the bandwidth $h$. Defining the long-run error variance by $\sigma^2$, we have $\var(\widehat{\psi}_T(u,h)) = \sigma^2 + o(1)$ for any fixed location $u$ and any bandwidth $h$ with $h \rightarrow 0$ and $Th \rightarrow \infty$, meaning that the statistics $\widehat{\psi}_T(u,h)$ should have approximately the same variance across $u$ and $h$ for sufficiently large sample sizes $T$. In what follows, we mainly consider normalized versions $\widehat{\psi}_T(u,h)/\widehat{\sigma}$ of the kernel averages $\widehat{\psi}_T(u,h)$, where $\widehat{\sigma}^2$ is an estimator of the long-run error variance $\sigma^2$. The problem of estimating $\sigma^2$ is discussed in detail in Section \ref{sec-error-var}. For the time being, we suppose that $\widehat{\sigma}^2$ is an estimator with reasonable theoretical properties. In particular, we assume that $\widehat{\sigma}^2 = \sigma^2 + O_p(1/\sqrt{T})$. 


Our multiscale statistic combines the kernel averages $\widehat{\psi}_T(u,h)$ for a wide range of different locations $u$ and bandwidths or scales $h$. Specifically, it takes into account all points $(u,h) \in \mathcal{G}_T$, where $\mathcal{G}_T$ is some subset of 
\begin{equation}\label{g-set}
\mathcal{G} =  \big\{ (u,h): [u-h,u+h] \subseteq [0,1] \text{ with } u \in [0,1] \text{ and } h \in [h_{\min},h_{\max}] \big\} 
\end{equation}
with $h_{\min}$ and $h_{\max}$ denoting some minimal and maximal bandwidth value respectively. In order our theory to work, we require the following conditions to hold:
\begin{enumerate}[label=(C\arabic*),leftmargin=1.05cm]
\setcounter{enumi}{3}

\item \label{C-grid} $|\mathcal{G}_T| = O(T^\gamma)$ for some arbitrarily large but fixed constant $\gamma > 0$, where $|\mathcal{G}_T|$ denotes the cardinality of $\mathcal{G}_T$. 

\item \label{C-h} $h_{\min} \gg T^{(2-q)/q}$  that is, $h_{\min} / T^{(2-q)/q} \rightarrow \infty$ with $q > 4$ defined in \ref{C-err2} and $h_{\max}< 1/2$.

\end{enumerate}
According to \ref{C-grid}, the number of points $(u,h)$ in $\mathcal{G}_T$ should not grow faster than $T^\gamma$ for some arbitrarily large but fixed $\gamma > 0$. This is a fairly weak restriction as it allows the set $\mathcal{G}_T$ to be extremely large as compared to the sample size $T$. For example, we may work with the set 
\begin{align*}
\mathcal{G}_T = \big\{ & (u,h): [u-h,u+h] \subseteq [0,1] \text{ with } u = t/T \text{ for some } 1 \le t \le T \\ & \text{ and } h \in [h_{\min},h_{\max}] \text{ with } h = t/T \text{ for some } 1 \le t \le T  \big\}
\end{align*}
which contains more than enough points $(u,h)$ for most practical applications. Condition \ref{C-h} imposes restrictions on the minimal and maximal bandwidths $h_{\min}$ and $h_{\max}$ used in our multiscale approach. However, these conditions are fairly weak, allowing us to choose the bandwidth window $[h_{\min},h_{\max}]$ extremely large. In particular, we can choose the minimal bandwidth $h_{\min}$ to be of the order $T^{-1/2}$ for any $q > 4$, which means that $h_{\min}$ converges to $0$ very quickly. Moreover, the maximal bandwidth $h_{\max}$ need not even converge to $0$, which implies that we can pick it very large.


%Our multiscale approach simultaneously takes into account a wide range of different locations $u$ and bandwidths or scales $h$, namely the points $(u,h)$ contained in the set 
%\[ \mathcal{G}_T = \big\{ (u,h): [u-h,u+h] \subseteq [0,1] \text{ with } u \in \mathcal{U}_T, h \in \mathcal{H}_T \text{ and } h_{\min} \le h \le h_{\max} \big\}. \]
%Here, $h_{\min}$ and $h_{\max}$ denote some minimal and maximal bandwidth values which are discussed in more detail below. Moreover, 
%\begin{align*} 
%\mathcal{U}_T & = \big\{ u \in [0,1]: u = t/M_T \text{ for some } 1 \le t \le M_T \big\} \\
%\mathcal{H}_T & = \big\{ h \in [0,1/2]: h = t/M_T^\prime \text{ for some } 1 \le t \le M_T^\prime \big\},
%\end{align*}
%where $\{M_T\}$ and $\{M_T^\prime\}$ are any sequences with $M_T = O(T^\gamma)$ and $M_T^\prime = O(T^{\gamma})$ for some arbitrarily large but fixed constant $\gamma > 0$, that is, $M_T$ and $M_T^\prime$ are allowed to grow as any fixed order polynomial of $T$ but they should not grow as fast as the exponential of $T$. 


Following the approach in \cite{DuembgenSpokoiny2001}, we define our multiscale statistic as 
\[ \widehat{\Psi}_T = \max_{(u,h) \in \mathcal{G}_T} \Big\{ \Big|\frac{\widehat{\psi}_T(u,h)}{\widehat{\sigma}}\Big| - \lambda(h) \Big\}, \] 
where $\lambda(h) = \sqrt{2 \log \{ 1/(2h) \}}$. As suggested there, we thus do not simply aggregate the individual statistics $\widehat{\psi}_T(u,h)/\widehat{\sigma}$ by taking the supremum over all points $(u,h) \in \mathcal{G}_T$ as in the traditional approach; we rather subtract the additive correction term $\lambda(h)$ from the statistics that correspond to the bandwidth level $h$. To see the heuristic idea behind the additive correction $\lambda(h)$, consider for a moment the uncorrected statistic
\[ \widehat{\Psi}_{T,\text{uncorrected}} = \max_{(u,h) \in \mathcal{G}_T} \Big|\frac{\widehat{\psi}_T(u,h)}{\widehat{\sigma}}\Big|. \]
For simplicity, assume that the errors $\varepsilon_t$ are i.i.d.\ normally distributed and neglect the estimation error in $\widehat{\sigma}$, that is, set $\widehat{\sigma} = \sigma$. Moreover, suppose that the set $\mathcal{G}_T$ only consists of points $(u_k,h_\ell) = ((2k - 1)h_\ell,h_\ell)$ with $k = 1,\ldots,\lfloor 1/2h_\ell \rfloor$ and $\ell = 1,\ldots,L$. In this case, we can write
\[ \widehat{\Psi}_{T,\text{uncorrected}} = \max_{1 \le \ell \le L} \max_{1 \le k \le \lfloor 1/2h_\ell \rfloor} \Big|\frac{\widehat{\psi}_T(u_k,h_\ell)}{\sigma}\Big|. \]
Under our simplifying assumptions, the statistics $\widehat{\psi}_T(u_k,h_\ell)/\sigma$ with $k = 1,\ldots,\lfloor 1/2h_\ell \rfloor$ are independent and standard normal for any given bandwidth $h_\ell$. Since the maximum over $\lfloor 1/2h \rfloor$ independent standard normal random variables is $\lambda(h) + o_p(1)$ as $h \rightarrow 0$, we obtain that $\max_{k} \widehat{\psi}_T(x_k,h_\ell)/\sigma$ is approximately of size $\lambda(h_\ell)$ for small bandwidths $h_\ell$. As $\lambda(h) \rightarrow \infty$ for $h \rightarrow 0$, this implies that $\max_{k} \widehat{\psi}_T(x_k,h_\ell)/\sigma$ tends to be much larger in size for small than for large bandwidth values. As a result, the stochastic behaviour of the uncorrected statistic $\widehat{\Psi}_{T,\text{uncorrected}}$ tends to be dominated by the statistics $\widehat{\psi}_T(x_k,h_\ell)$ corresponding to small bandwidth values $h_\ell$. The additively corrected statistic $\widehat{\Psi}_T$, in contrast, puts the statistics $\widehat{\psi}_T(x_k,h_\ell)$ corresponding to different bandwidth values $h_\ell$ on a more equal footing, thus counteracting the dominance of small bandwidth values. 


\subsection{The test procedure}\label{subsec-method-test}


In order to formulate a test for the hypothesis $H_0: m = 0$, we still need to specify a critical value. To do so, we define the statistic
\[ \Phi_T^* = \max_{(u,h) \in \mathcal{G}_T} \Big\{ \Big|\frac{\phi_T^*(u,h)}{\sigma}\Big| - \lambda(h) \Big\}, \] 
where
\[ \phi_T^*(u,h) = \sum\limits_{t=1}^T w_{t,T}(u,h) \, \sigma Z_t \]
and $Z_t$ are independent standard normal random variables. The statistic $\Phi_T^*$ can be regarded as a Gaussian version of the test statistic $\widehat{\Psi}_T$ under the null hypothesis $H_0$. Let $q_T(\alpha)$ be the $(1-\alpha)$-quantile of $\Phi_T^*$. Importantly, the quantile $q_T(\alpha)$ can be computed by Monte Carlo simulations and can thus be regarded as known. Our multiscale test of the hypothesis $H_0: m = 0$ is now defined as follows: For a given significance level $\alpha \in (0,1)$, we reject $H_0$ if $\widehat{\Psi}_T > q_T(\alpha)$. 


\subsection{Theoretical properties of the test}\label{subsec-method-theo}


In order to examine the theoretical properties of our multiscale test, we introduce the statistic 
\begin{align*}
\widehat{\Phi}_T 
 & = \max_{(u,h) \in \mathcal{G}_T} \Big\{ \Big| \frac{\widehat{\psi}_T(u,h) - \ex \widehat{\psi}_T(u,h)}{\widehat{\sigma}} \Big| - \lambda(h) \Big\} \\
 & = \max_{(u,h) \in \mathcal{G}_T} \Big\{ \Big| \frac{\widehat{\phi}_T(u,h)}{\widehat{\sigma}} \Big| - \lambda(h) \Big\} 
\end{align*}
with 
\[ \widehat{\phi}_T(u,h) = \sum\limits_{t=1}^T w_{t,T}(u,h) \varepsilon_t. \]
According to the following theorem, for any given $\alpha \in (0,1)$, the $(1-\alpha)$-quantile of the statistic $\widehat{\Phi}_T$ is approximately equal to the (known) quantile $q_T(\alpha)$ of $\Phi_T^*$ defined in Section \ref{subsec-method-test}. 
\begin{theorem}\label{theo-stat}
Let \ref{C-err1}--\ref{C-h} be fulfilled and suppose that the kernel $K$ is Lipschitz continuous and has compact support $[-1,1]$. Then 
\[ \pr \big( \widehat{\Phi}_T \le q_T(\alpha) \big) = (1 - \alpha) + o(1). \]
\end{theorem}
A full proof of Theorem \ref{theo-stat} is given in the Appendix. 
%We here shortly outline the proof strategy, which is of broader interest as it can potentially be applied in the context of a variety of other statistical multiscale problems. The strategy splits up into two main steps: 
We here shortly outline the proof strategy, which splits up into two main steps: In the first, we replace the statistic $\widehat{\Phi}_T$ for each $T \ge 1$ by a statistic $\widetilde{\Phi}_T$ with the same distribution as $\widehat{\Phi}_T$ and the property that 
\begin{equation}\label{eq-theo-stat-strategy-step1}
\big| \widetilde{\Phi}_T - \Phi_T^* \big| = o_p \Big( \frac{T^{1/q}}{\sqrt{T h_{\min}}} \Big),
\end{equation}
where the Gaussian statistic $\Phi_T^*$ is defined in Section \ref{subsec-method-test}. We thus replace the test statistic $\widehat{\Phi}_T$ by an identically distributed version which is close to a Gaussian statistic whose distribution is known. To do so, we make use of strong approximation theory for dependent processes as derived in \cite{BerkesLiuWu2014}. In the second step, we show that 
\begin{equation}\label{eq-theo-stat-strategy-step2}
\sup_{x \in \reals} \big| \pr(\widetilde{\Phi}_T \le x) - \pr(\Phi_T^* \le x) \big| = o(1), 
\end{equation}
which implies that that for any given $\alpha \in (0,1)$, the $(1-\alpha)$-quantile of the statistic $\widetilde{\Phi}_T$ can be approximated by the known quantile $q_T(\alpha)$ of the Gaussian statistic $\Phi_T^*$. The main tools for verifying \eqref{eq-theo-stat-strategy-step2} are anti-concentration results for Gaussian random vectors as derived in \cite{Chernozhukov2015}. Combining \eqref{eq-theo-stat-strategy-step1} and \eqref{eq-theo-stat-strategy-step2}, we finally arrive at the statement of Theorem \ref{theo-stat}. 


With the help of Theorem \ref{theo-stat}, we can now investigate the theoretical properties of our multiscale test. The first result is an immediate consequence of Theorem \ref{theo-stat}. It says that the test has the correct (asymptotic) size. 
\begin{corollary}\label{corollary-test-1}
Let the conditions of Theorem \ref{theo-stat} be satisfied. Under the null hypothesis $H_0$, it holds that 
\[ \pr \big( \widehat{\Psi}_T \le q_T(\alpha) \big) = (1 - \alpha) + o(1). \]
\end{corollary}
The second result characterizes the power of the multiscale test. According to it, the test has asymptotic power $1$ against fixed alternatives and is thus consistent. 
\begin{corollary}\label{corollary-test-2}
Let the conditions of Theorem \ref{theo-stat} be satisfied and let $m$ be any fixed function with $m \ne 0$. Then 
\[ \pr \big( \widehat{\Psi}_T \le q_T(\alpha) \big) = o(1). \]
\end{corollary}
To formulate the next result, we define 
\begin{equation}\label{pi-set}
\Pi_T = \big\{ I_{u,h} = [u-h,u+h]: (u,h) \in \mathcal{A}_T \big\}
\end{equation}
with 
\begin{equation}\label{a-set}
\mathcal{A}_T = \Big\{ (u,h) \in \mathcal{G}_T: \Big|\frac{\widehat{\psi}_T(u,h)}{\widehat{\sigma}}\Big| - \lambda(h) > q_T(\alpha) \Big\}.
\end{equation}
$\Pi_T$ is the collection of intervals $I_{u,h} = [u-h,u+h]$ for which the (corrected) test statistic $|\widehat{\psi}_T(u,h)| - \lambda(h)$ lies above the critical value $q_T(\alpha)$. With this notation at hand, we consider the event 
\[ E_T = \Big\{ \forall I_{u,h} \in \Pi_T: m(v) \ne 0 \text{ for some } v \in I_{u,h} = [u-h,u+h] \Big\}. \]
This is the event that the null hypothesis is violated on all intervals $I_{u,h}$ for which the (corrected) test statistic $|\widehat{\psi}_T(u,h)/\widehat{\sigma}| - \lambda(h)$ is above the critical value $q_T(\alpha)$. We can make the following formal statement about the event $E_T$. 
\begin{corollary}\label{corollary-test-3}
Under the conditions of Theorem \ref{theo-stat}, it holds that  
\[ \pr \big( E_T \big) \ge (1-\alpha) + o(1). \] 
\end{corollary}
According to Corollary \ref{corollary-test-3}, our test procedure allows us to make uniform confidence statements of the following form: With (asymptotic) probability at least $(1-\alpha)$, the null hypothesis $H_0: m = 0$ is violated on all the intervals $I_{u,h} \in \Pi_T$. Hence, our multiscale test does not only allow us to check whether the null hypothesis is violated. It also allows us to identify the regions where violations occur with a pre-specified level of confidence. 
 

The statement of Corollary \ref{corollary-test-3} suggests to graphically present the results of our multiscale test by plotting the intervals $I_{u,h} \in \Pi_T$, that is, by plotting the intervals where (with asymptotic probability $\ge 1-\alpha$) our test detects a violation of the null hypothesis. The drawback of this graphical presentation is that the number of intervals in $\Pi_T$ is often quite large. To obtain a better graphical summary of the results, we replace $\Pi_T$ by a subset $\Pi_T^*$ which is constructed as follows: As in ??, we call an interval $I_{u,h} \in \Pi_T$ minimal if there is no other interval $I_{u^\prime,h^\prime} \in \Pi_T$ with $I_{u^\prime,h^\prime} \subset I_{u,h}$. Let $\Pi_T^*$ be the collection of all minimal intervals in $\Pi_T$ and define the event 
\[ E_T^* = \Big\{ \forall I_{u,h} \in \Pi_T^*: m(v) \ne 0 \text{ for some } v \in I_{u,h} = [u-h,u+h] \Big\}. \]
It is easily seen that $E_T = E_T^*$. Hence, by Corollary \ref{corollary-test-3}, it holds that
\[ \pr \big( E_T^* \big) \ge (1-\alpha) + o(1). \] 
This suggests to plot the minimal intervals in $\Pi_T^*$ rather than the whole collection of intervals $\Pi_T$ as a graphical summary of the test results. We in particular use this way of presenting the test results in our application examples of Section ??. 



\newpage
\section{Testing for shape constraints of a time trend}\label{sec-test-shape}

In this section we adapt the multiscale test method developed above %in Section \ref{subsec-method-stat}
to test the hypothesis $H_0$: ``$m$ is constant''. This hypothesis is essentially equivalent to testing another hypothesis $\widetilde{H}_0: m'=0$, therefore, the procedure itself and the underlying theory very closely follows Section \ref{sec-method}. Hence, similar arguments will be omitted for the sake of brevity.

\subsection{Construction of the test statistic}\label{subsec-test-shape-stat}

As in Section \ref{subsec-method-stat}, in order to test the hypothesis $H_0$: ``$m$ is constant'' in the model \eqref{model1} we first consider the kernel averages similar to those in \eqref{kernel-ave}
\begin{equation}\label{kernel-ave-shape}
\widehat{\psi}_T(u,h) = \sum\limits_{t=1}^T \widetilde{w}_{t,T}(u,h) Y_t, 
\end{equation}
where $u\in [0,1]$, $h$ is the bandwidth parameter and $\widetilde{w}_{t,T}(u,h)$ is a differential kernel average: 
\[ \widetilde{w}_{t,T}(u,h) = \frac{1}{\|K'\|_{u,h,T}} K'\Big( \frac{u - t/T}{h} \Big) \, \quad \text{with} \quad \|K'\|_{u,h,T} = \Big\{\sum\limits_{t=1}^T  (K')^2\Big( \frac{u - t/T}{h} \Big)\Big\}.^{1/2} \]
Here $K'$ is the first derivative of a non-negative kernel function $K$, which is as in Section \ref{subsec-method-stat} symmetric about zero, integrates to one and has compact support $[-1,1]$.

As before, for any fixed location $u$ we have $\var(\widehat{\psi}_T(u,h)) = \sigma^2 + o(1)$ under $h \rightarrow 0$ and $Th \rightarrow \infty$, where $\sigma^2$ is long-run error variance. In the following sections we mainly consider normalized versions $\widehat{\psi}_T(u,h)/\widehat{\sigma}$ of the kernel averages $\widehat{\psi}_T(u,h)$, where $\widehat{\sigma}^2$ is a $\sqrt{T}$-consistent estimator of $\sigma^2$.

Our multiscale statistic is then analogously defined as 
\[ \widehat{\Psi}_T = \max_{(u,h) \in \mathcal{G}_T} \Big\{ \Big|\frac{\widehat{\psi}_T(u,h)}{\widehat{\sigma}}\Big| - \lambda(h) \Big\} \] 
with $\lambda(h) = \sqrt{2 \log \{ 1/(2h) \}}$ and $\mathcal{G}_T$ being a subset of $\mathcal{G}$ from \eqref{g-set}. The additive correction term $\lambda(h)$ is substracted from the statistics due to the same arguments as in Section \ref{subsec-method-stat} and in \cite{DuembgenSpokoiny2001}.


\subsection{The test procedure}\label{subsec-test-shape-test}

In order to be able to reject or accept our null hypothesis, we need to compare it with some prespecified critical values. These critical values are then found using the Gaussian version $\Phi_T^*$ of the test statistic $\widehat{\Psi}_T$ under the null hypothesis $H_0$:
\[ \Phi_T^* = \max_{(u,h) \in \mathcal{G}_T} \Big\{ \Big|\frac{\phi_T^*(u,h)}{\sigma}\Big| - \lambda(h) \Big\}, \] 
where
\[ \phi_T^*(u,h) = \sum\limits_{t=1}^T \tilde{w}_{t,T}(u,h) \, \sigma Z_t \]
and $Z_t$ are independent standard normal random variables. The $(1-\alpha)$-quantile of $\Phi_T^*$, denoted further as $q_T(\alpha)$, can thus be computed by Monte Carlo simulations. Our multiscale test of the hypothesis $H_0$: ``$m$ is constant'' is defined as follows: For a given significance level $\alpha \in (0,1)$, we reject $H_0$ if $\widehat{\Psi}_T > q_T(\alpha)$. 


\subsection{Theoretical properties of the test}\label{subsec-test-shape-theo}

As in Section \ref{subsec-method-theo}, we first investigate theoretical properties of the auxiliary statistic 
\begin{align*}
\widehat{\Phi}_T 
 & = \max_{(u,h) \in \mathcal{G}_T} \Big\{ \Big| \frac{\widehat{\psi}_T(u,h) - \ex \widehat{\psi}_T(u,h)}{\widehat{\sigma}} \Big| - \lambda(h) \Big\} \\
 & = \max_{(u,h) \in \mathcal{G}_T} \Big\{ \Big| \frac{\widehat{\phi}_T(u,h)} {\widehat{\sigma}} \Big| - \lambda(h) \Big \} 
\end{align*}
with 
\[ \widehat{\phi}_T(u,h) = \sum\limits_{t=1}^T \widetilde{w}_{t,T}(u,h) \varepsilon_t. \]


The main result in this Section is an adaptation of the Theorem \ref{theo-stat} to our current test problem. According to it, for any given $\alpha \in (0,1)$ we can use the known quantiles $q_T(\alpha)$ of $\Phi_T^*$ to accept or reject our hypothesis. More formally, the result is formulated as follows. 
\begin{theorem}\label{theo-stat-shape}
Let \ref{C-err1}--\ref{C-h} be fulfilled and suppose that the first derivative of the kernel $K'$ is Lipschitz continuous and has compact support $[-1,1]$. Then 
\[ \pr \big( \widehat{\Phi}_T \le q_T(\alpha) \big) = (1 - \alpha) + o(1). \]
\end{theorem}
The proof of Theorem \ref{theo-stat-shape} goes in parallel to the one of Theorem \ref{theo-stat}, and thereby omitted.

As in Section \ref{subsec-method-theo}, the theoretical properties of our multiscale test are immediate consequences of the Theorem \ref{theo-stat-shape}. 
\begin{corollary}\label{corollary-test-shape-1}
Let the conditions of Theorem \ref{theo-stat-shape} be satisfied. Under the null hypothesis $H_0$: ``$m$ is constant'', it holds that 
\[ \pr \big( \widehat{\Psi}_T \le q_T(\alpha) \big) = (1 - \alpha) + o(1). \]
\end{corollary}
\begin{corollary}\label{corollary-test-shape-2}
Let the conditions of Theorem \ref{theo-stat-shape} be satisfied and let $m$ be any fixed non-constant function. Then 
\[ \pr \big( \widehat{\Psi}_T \le q_T(\alpha) \big) = o(1). \]
\end{corollary}

With $\Pi_T$ and $\mathcal{A}_T$ defined as in \eqref{pi-set} and \eqref{a-set} respectively, we now consider the event 
\[ \widetilde{E}_T = \Big\{ \forall I_{u,h} \in \Pi_T: m'(v) \ne 0 \text{ for some } v \in I_{u,h} = [u-h,u+h] \Big\}. \]
This is the event that our current null hypothesis is violated on all intervals $I_{u,h}$ for which the (corrected) test statistic $|\widehat{\psi}_T(u,h)/\widehat{\sigma}| - \lambda(h)$ is above the critical value $q_T(\alpha)$. Proceding further as in Section \ref{subsec-method-theo}, we arrive at the following result regarding $\widetilde{E}_T$. 
\begin{corollary}\label{corollary-test-shape-3}
Under the conditions of Theorem \ref{theo-stat-shape}, it holds that  
\[ \pr \big( \widetilde{E}_T \big) \ge (1-\alpha) + o(1). \] 
\end{corollary}

As before, Corollary \ref{corollary-test-shape-3} allows us to specify the regions where violation of the null hypothesis occurs with (asymptotic) probability at least $(1-\alpha)$.

\newpage
\section{Testing for equality of time trends}\label{sec-test-equality}

In this section we adapt the multiscale test method developed in Section \ref{sec-method} 
to test the hypothesis that the trend functions in different time series are equal. More formally, the null hypothesis is formulated as $H_0: m_1 = m_2 = \ldots = m_N$ in the model \eqref{model2}. To test 

\subsection{Construction of the test statistic}\label{subsec-test-equality-stat}

In order to test the hypothesis, we modify the baseline procedure from Section \ref{subsec-method-stat} as follows: For any pair of time series $i$ and $j$, we define

\begin{equation}\label{kernel-ave-equality}
\widehat{\psi}_{ij,T}(u,h) = \sum\limits_{t=1}^T w_{t,T}(u,h) (Y_{it} - Y_{jt}), 
\end{equation}
where $u\in [0,1]$, $h$ is the bandwidth parameter and $w_{t,T}(u,h)$ is a kernel average: 
\[ w_{t,T}(u,h) = \frac{1}{\|K\|_{u,h,T}} K\Big( \frac{u - t/T}{h} \Big) \, \quad \text{with} \quad \|K\|_{u,h,T} = \Big\{\sum\limits_{t=1}^T  K^2\Big( \frac{u - t/T}{h} \Big)\Big\}^{1/2}_. \]
Here $K$ is a non-negative kernel function, which is as in Section \ref{subsec-method-stat} symmetric about zero, integrates to one and has compact support $[-1,1]$.

Letting 
\[ \widehat{\Psi}_{ij,T} = \max_{(u,h) \in \mathcal{G}_T} \Big\{ \Big|\frac{\widehat{\psi}_{ij,T}(u,h)}{\sqrt{2}\widehat{\sigma}}\Big| - \lambda(h) \Big\} \] 
with $\lambda(h) = \sqrt{2 \log \{ 1/(2h) \}}$ and $\mathcal{G}_T$ being a subset of $\mathcal{G}$ from \eqref{g-set},
we define our multiscale statistic $\widehat{\Psi}_T$ as
\[ \widehat{\Psi}_T = \max_{1 \le i < j \le N} \widehat{\Psi}_{ij,T}. \]

%As before, for any fixed location $u$ we have $\var(\widehat{\psi}_T(u,h)) = \sigma^2 + o(1)$ under $h \rightarrow 0$ and $Th \rightarrow \infty$, where $\sigma^2$ is long-run error variance. In the following sections we mainly consider normalized versions $\widehat{\psi}_T(u,h)/\widehat{\sigma}$ of the kernel averages $\widehat{\psi}_T(u,h)$, where $\widehat{\sigma}^2$ is a $\sqrt{T}$-consistent estimator of $\sigma^2$.

\subsection{The test procedure}\label{subsec-test-equality-test}

Critical values for the statistics $\widehat{\Psi}_T$ are found using the Gaussian version $\Phi_T^*$ of it under the null hypothesis $H_0$:
\begin{align*}
&\Phi_T^* = \max_{1\le i < j \le N} \Phi_{ij, T}^*,\\
&\Phi_{ij, T}^* =  \max_{(u,h) \in \mathcal{G}_T} \Big\{ \Big|\frac{\phi_{ij,T}^*(u,h)}{\sqrt{2} \sigma}\Big| - \lambda(h) \Big\},
\end{align*} 
where
\[ \phi_{ij,T}^*(u,h) = \sum\limits_{t=1}^T w_{t,T}(u,h) \, (\sigma Z_{i,t} - \sigma Z_{j,t}) \]
and for every $i \in \{1, \ldots, N\}$ $(Z_{i,t})_t$ are independent standard normal random variables.
 
We can compute the $(1-\alpha)$-quantile of $\Phi_T^*$, denoted further as $q_T(\alpha)$, by Monte Carlo simulations, and thus it can be regarded as a known value. Our multiscale test of the hypothesis $H_0: m_1 = m_2 = \ldots = m_N$ is defined as follows: For a given significance level $\alpha \in (0,1)$, we reject $H_0$ if $\widehat{\Psi}_T > q_T(\alpha)$. 

\subsection{Theoretical properties of the test}\label{subsec-test-equality-theo}

As in previous sections, we first introduce auxiliary statistic 
\begin{align*}
\widehat{\Phi}_T &= \max_{1\le i < j \le N} \widehat{\Phi}_{ij, T},\\
\widehat{\Phi}_{ij,T} 
 & = \max_{(u,h) \in \mathcal{G}_T} \Big\{ \Big| \frac{\widehat{\psi}_{ij,T}(u,h) - \ex \widehat{\psi}_{ij,T}(u,h)}{\sqrt{2}\widehat{\sigma}} \Big| - \lambda(h) \Big\} \\
 & = \max_{(u,h) \in \mathcal{G}_T} \Big\{ \Big| \frac{\widehat{\phi}_{ij,T}(u,h)} {\sqrt{2}\widehat{\sigma}} \Big| - \lambda(h) \Big \} 
\end{align*}
with 
\[ \widehat{\phi}_{ij,T}(u,h) = \sum\limits_{t=1}^T w_{t,T}(u,h) (\varepsilon_{i,t} - \varepsilon_{j,t}). \]


The main result in this Section is very similar to the results in previous sections. It states that for any given $\alpha \in (0,1)$ we can use the known quantiles $q_T(\alpha)$ of $\Phi_T^*$ to reject our null hypothesis.
\begin{theorem}\label{theo-stat-equality}
Let \ref{C-err1}--\ref{C-h} be fulfilled and suppose that the kernel function $K$ is Lipschitz continuous and has compact support $[-1,1]$. Then 
\[ \pr \big( \widehat{\Phi}_T \le q_T(\alpha) \big) = (1 - \alpha) + o(1). \]
\end{theorem}
The proof of Theorem \ref{theo-stat-equality} goes follows closely the one of Theorem \ref{theo-stat} and is given in the Appendix.

As in Section \ref{subsec-method-theo}, the following corollaries, which characterize theoretical properties of our multiscale test, are immediate consequences of the Theorem \ref{theo-stat-equality}. 
\begin{corollary}\label{corollary-test-equality-1}
Let the conditions of Theorem \ref{theo-stat-equality} be satisfied. Under the null hypothesis $H_0: m_1 = m_2 = \ldots = m_N$, it holds that 
\[ \pr \big( \widehat{\Psi}_T \le q_T(\alpha) \big) = (1 - \alpha) + o(1). \]
\end{corollary}
\begin{corollary}\label{corollary-test-equality-2}
Let the conditions of Theorem \ref{theo-stat-equality} be satisfied and let $m$ be any fixed non-constant function. Then 
\[ \pr \big( \widehat{\Psi}_T \le q_T(\alpha) \big) = o(1). \]
\end{corollary}

%With $\Pi_T$ and $\mathcal{A}_T$ defined as in \eqref{pi-set} and \eqref{a-set} respectively, we now consider the event 
%\[ \widetilde{E}_T = \Big\{ \forall I_{u,h} \in \Pi_T: m'(v) \ne 0 \text{ for some } v \in I_{u,h} = [u-h,u+h] \Big\}. \]
%This is the event that our current null hypothesis is violated on all intervals $I_{u,h}$ for which the (corrected) test statistic $|\widehat{\psi}_T(u,h)/\widehat{\sigma}| - \lambda(h)$ is above the critical value $q_T(\alpha)$. Proceding further as in Section \ref{subsec-method-theo}, we arrive at the following result regarding $\widetilde{E}_T$. 
%\begin{corollary}\label{corollary-test-shape-3}
%Under the conditions of Theorem \ref{theo-stat-shape}, it holds that  
%\[ \pr \big( \widetilde{E}_T \big) \ge (1-\alpha) + o(1). \] 
%\end{corollary}

%As before, Corollary \ref{corollary-test-shape-3} allows us to specify the regions where violation of the null hypothesis occurs with (asymptotic) probability at least $(1-\alpha)$.

\newpage
\section{Estimation of the long-run error variance}\label{sec-error-var}

For estimating the long-run error covariance $\sigma^2 = \sum_{k \in \integers} \ex[\varepsilon_0 \varepsilon_k]$ various consistent estimators can be used. Here we employ the difference-based method proposed by \cite{Hall2003} which has the advantage that it does not depend on a bandwidth parameter. The exact procedure of constructing $\hat{\sigma}^2$ is described below.

As in the previous sections, we allow for dependency structure in the errors. Specifically, we assume that the errors $\epsilon_1, \ldots, \epsilon_T$ have the following linear structure:
\begin{align*}
\epsilon_t = \sum_{s=1}^{p} \phi_s \epsilon_{t-s} + e_t
\end{align*}
for some $p \le 1$, where $\{e_t\}_{-\infty}^{+\infty}$ are i.i.d. with $\ex[e_t] = 0$ and $\Var[e_t] = \sigma^2_e < \infty$. Furthermore, we assume that the process $\{\epsilon_t\}$ is causal, that is the constants $\phi_1, \ldots, \phi_p$ are such that the equation $1-\sum_{j}\phi_j z^j = 0$ has no complex roots inside the unit circle. Under these assumptions we can construct a $\sqrt{T}$-consistent estimator $\hat{\sigma}^2$ in three following steps.
\vspace{1pt}


\textit{Step 1.}
First we focus our attention on  the error covariance at lag $s$: $\gamma_s = cov(\epsilon_t, \epsilon_{t-s})$. Here we exploit pairwise differences of the $Y_t$s: for a given $s \in \integers$ define the difference operator $D_s: (D_s Y)_t = Y_t - Y_{t-s}$. Then 
%\[(D_s Y)_t = (D_s m(\cdot))_t + (D_s \epsilon)_t ,\]
the estimators are constructed as follows:
\begin{align*}
\hat{\gamma}(0) &= \frac{1}{m_2-m_1+1}\sum_{m=m_1}^{m_2}\frac{1}{2(T-m)}\sum_{t=m+1}^T\{(D_mY)_t\}^2,\\
\hat{\gamma}(s) &= \hat{\gamma}(0) - \frac{1}{2(T-s)}\sum_{t=s+1}^T \{(D_sY)_t\}^2 \text{ for } s\ge 1,\\
\hat{\gamma}(s) &= \hat{\gamma}(-s) \text{ for } s\le -1,
\end{align*}
where $m_1\le m_2$ are subsidiary smoothing parameters.
\vspace{1pt}


\textit{Step 2.}
Now we can estimate coefficients of the eror model $\phi_s$ by using the Yule-Walker equations:
\[\gamma(s) = \sum_{r\ge 1}\phi_r\gamma(s-r).\]
Then denoting $A$ the $p\times p$ matrix of error covariance with elements $a_{s_1,s_2} = \gamma(s_1-s_2)$ and replacing $\gamma$ by $\hat{\gamma}$ in the definition of $A$ to obtain an estimator $\hat{A}$, straightforwardly we have estimators for the coefficients of the model:
\[(\hat{\phi}_1, \ldots, \hat{\phi}_p)^T = \hat{A}^{-1} (\hat{\gamma}(1), \ldots, \hat{\gamma}(p))^T\]


\textit{Step 3.}
The estimators $\hat{\gamma}(s)$ from the previous step do not exploit the structure of the process $\epsilon_t$ which can lead to unreasonably high variability of $\hat{\gamma}(s)$ for large $s$. For this reason we can modify the approach in Step 1 so that it extracts more infromation from the dependency structure between the errors $\epsilon_t$.

Once the estimators $\hat{\phi}_1, \ldots, \hat{\phi}_p$ are constructed, define $\hat{\psi}_1, \hat{\psi}_1, \ldots$ by 
\[1 + \sum_{j \ge 1} \hat{\psi}_j z^j = \Big(1 - \sum_{j=1}^p \hat{\phi}_j z^j \Big)^{-1} \]
and let $\hat{\psi}_0 = 1$. Furthermore, define $\bar{\gamma}(0), \bar{\gamma}(1), \ldots$ by
\[\bar{\gamma}(s) = \underset{k, l \ge 0, k+l=s}{\sum\sum} \hat{\psi}(k)\hat{\psi}(l).\]
Then $\hat{\sigma}_e^2 = \hat{\gamma}(0)\bar{\gamma}(0)$ would be a suitable estimator of $\sigma^2_e = \var[e_t]$. And if we define $\tilde{\gamma}(s) = \hat{\sigma}_e^2 \bar{\gamma}(s)$ for $s\ge 1$, we will obtain an estimator for $\sigma^2 = \sum_{k\in \integers} \ex[\epsilon_0 \epsilon_k] = \gamma(0) + 2\sum_{s\ge 1}\gamma(s)$ using the following formula:
\[\hat{\sigma} = \hat{\sigma}^2_e \Big( 1-\sum_{1\le j\le p}\hat{\psi}_j\Big)^{-2}.\]

It may be proved that if the error distribution has finite fourth moment, if smoothing parameters are such that $m_1 \le m_2, m_1/\log(T) \rightarrow \infty$ and $m_2 = O(\sqrt{T})$ and under mild smoothness conditions on $m(x)$ we have 
\begin{align*}
\max_{0\le s \le T} |\hat{\gamma}(s) - \gamma(s)| &= O_p(\frac{1}{\sqrt{T}}) \text{ and} \\
\max_{0\le j \le p} |\hat{\phi}(j) - \phi(j)| &= O_p(\frac{1}{\sqrt{T}}) \\
\hat{\sigma}^2 - \sigma^2 &= O_p (\frac{1}{\sqrt{T}})
\end{align*}
\vspace{1pt}

\newpage
\section*{Appendix}

\def\theequation{A.\arabic{equation}}
\setcounter{equation}{0}
\allowdisplaybreaks[3]


In this appendix, we prove the main theoretical results of the paper. Throughout the appendix, the symbol $C$ denotes a universal real constant which may take a different value on each occurrence. We use the following notation: For $a,b \in \reals$, we write $a_+ = \max \{0,a\}$ and $a \vee b = \max\{a,b\}$. For any set $A$, the symbol $|A|$ denotes the cardinality of $A$. The notation $X \stackrel{\mathcal{D}}{=} Y$ means that the two random variables $X$ and $Y$ have the same distribution. Finally, $f_0(\cdot)$ and $F_0(\cdot)$ denote the density and distribution function of the standard Gaussian distribution, respectively.



\subsection*{Proof of Theorem \ref{theo-stat}}


As already outlined in Section \ref{subsec-method-theo}, the proof splits up into two main steps. In the first, we use strong approximation theory to show the following result: 
\begin{propA}\label{prop1-theo-stat}
Under the conditions of Theorem \ref{theo-stat}, there exist statistics $\widetilde{\Phi}_T$ for $T = 1,2,\ldots$ with the following two properties: (i) $\widetilde{\Phi}_T$ has the same distribution as $\widehat{\Phi}_T$ for any $T$, and (ii)
\[ \big| \widetilde{\Phi}_T - \Phi_T^* \big| = o_p \Big( \frac{T^{1/q}}{\sqrt{T h_{\min}}} \Big), \]
where $\Phi_T^*$ is a Gaussian statistic as defined in Section \ref{subsec-method-test}. 
\end{propA}
According to this result, we can replace the statistic $\widehat{\Phi}_T$ by an identically distributed version $\widetilde{\Phi}_T$ which is close to the Gaussian statistic $\Phi_T^*$. We defer the proof of Proposition \ref{prop1-theo-stat} until the arguments for Theorem \ref{theo-stat} are completed. In the second main step of the proof, we show that 
\begin{equation}\label{eq-theo-stat-step2}
\sup_{x \in \reals} \big| \pr(\widetilde{\Phi}_T \le x) - \pr(\Phi_T^* \le x) \big| = o(1), 
\end{equation}
which immediately implies the statement of Theorem \ref{theo-stat}. For the proof of \eqref{eq-theo-stat-step2}, we use the following simple lemma: 
\begin{lemmaA}\label{lemma1-theo-stat}
Let $V_T$ and $W_T$ be real-valued random variables for $T = 1,2,\ldots$ such that $V_T = O_p(1)$ and $V_T - W_T = o_p(\delta_T)$ with $\delta_T = o(1)$. If 
\begin{equation}\label{eq-lemma1-cond}
\sup_{x \in \reals} \pr(|V_T - x| \le \delta_T) = o(1), 
\end{equation}
then 
\begin{equation}\label{eq-lemma1-statement}
\sup_{x \in \reals} \big| \pr(V_T \le x) - \pr(W_T \le x) \big| = o(1). 
\end{equation}
\end{lemmaA}
The statement of this lemma can be summarized as follows: If $W_T$ can be approximated by $V_T$ in the sense that $V_T - W_T = o_p(\delta_T)$ and if $V_T$ does not concentrate too strongly in small regions of the form $[x - \delta_T,x+\delta_T]$ as assumed in \eqref{eq-lemma1-cond}, then the distribution of $W_T$ can be approximated by that of $V_T$ in the sense of \eqref{eq-lemma1-statement}.
\begin{proof}[\textnormal{\textbf{Proof of Lemma \ref{lemma1-theo-stat}}}] 
It holds that 
\begin{align*}
 & \big| \pr(V_T \le x) - \pr(W_T \le x) \big| \\
 & = \big| \ex \big[ 1(V_T \le x) - 1(W_T \le x) \big] \big| \\
 & \le \big| \ex \big[ \big\{ 1(V_T \le x) - 1(W_T \le x) \big\} 1(|V_T - W_T| \le \delta_T) \big] + \ex \big[ 1(|V_T - W_T| > \delta_T) \big] \big| \\
 & \le \ex \big[ 1(|V_T - x| \le \delta_T, |V_T - W_T| \le \delta_T) \big] + o(1) \\
 & \le \pr (|V_T - x| \le \delta_T) + o(1). \qedhere
\end{align*}
\end{proof}
We now apply Lemma \ref{lemma1-theo-stat} with $V_T = \Phi^*_T$, $W_T = \widetilde{\Phi}_T$ and $\delta_T = T^{1/q} / \sqrt{T h_{\min}}$: Using L{\'e}vy's modulus of continuity, it can be shown that $\Phi_T^* = O_p(1)$. Moreover, from Proposition \ref{prop1-theo-stat}, we already know that $\widetilde{\Phi}_T - \Phi_T^* = o_p(\delta_T)$. Finally, with the help of recent anti-concentration bounds for Gaussian random vectors, we can verify the following proposition.
\begin{propA}\label{prop2-theo-stat}
Under the conditions of Theorem \ref{theo-stat}, it holds that 
\[ \sup_{x \in \reals} \pr \Big( | \Phi_T^* - x | \le \delta_T \Big) = o(1). \]
\end{propA}
The proof of Proposition \ref{prop2-theo-stat} is given below. According to it, the Gaussian multiscale statistic $\Phi_T^*$ does not concentrate too strongly in regions of the form $[x - \delta_T,x + \delta_T]$. Putting everything together, we are now in a position to apply Lemma \ref{lemma1-theo-stat}, which in turn yields \eqref{eq-theo-stat-step2}. This completes the proof of Theorem \ref{theo-stat}. 



\subsubsection*{Proof of Proposition \ref{prop1-theo-stat} -- strong approximation theory}


For the proof, we draw on strong approximation theory for stationary processes $\{\varepsilon_t\}$ that fulfill the conditions \ref{C-err1}--\ref{C-err3}. By Theorem 2.1 and Corollary 2.1 in \cite{BerkesLiuWu2014}, the following strong approximation result holds true: On a richer probability space, there exists a standard Brownian motion $\mathbb{B}$ and a sequence $\{ \widetilde{\varepsilon}_t: 1 \le t \le T \}$ with $[\widetilde{\varepsilon}_1,\ldots,\widetilde{\varepsilon}_T] \stackrel{\mathcal{D}}{=} [\varepsilon_1,\ldots,\varepsilon_T]$ such that 
\begin{equation}\label{eq-strongapprox-dep}
\max_{1 \le t \le T} \Big| \sum\limits_{s=1}^t \widetilde{\varepsilon}_s - \sigma \mathbb{B}(t) \Big| = o\big( T^{1/q} \big) \quad \text{a.s.},  
\end{equation}
where $\sigma^2 = \sum_{k \in \integers} \ex[\varepsilon_0 \varepsilon_k]$ denotes the long-run error variance. To apply this result, we set 
\[ \widetilde{\Phi}_T = \max_{(u,h) \in \mathcal{G}_T} \Big\{ \Big|\frac{\widetilde{\phi}_T(u,h)}{\widehat{\sigma}}\Big| - \lambda(h) \Big\} \]
with $\widetilde{\phi}_T(u,h) = \sum\nolimits_{t=1}^T w_{t,T}(u,h) \widetilde{\varepsilon}_t$ as well as 
\begin{align*}
\Phi_T^* & = \max_{(u,h) \in \mathcal{G}_T} \Big\{ \Big|\frac{\phi_T^*(u,h)}{\sigma}\Big| - \lambda(h) \Big\} \\
\Phi_T^{**} & = \max_{(u,h) \in \mathcal{G}_T} \Big\{ \Big|\frac{\phi_T^*(u,h)}{\widehat{\sigma}}\Big| - \lambda(h) \Big\} 
\end{align*}
with $\phi_T^*(u,h) = \sum\nolimits_{t=1}^T w_{t,T}(u,h) \sigma Z_t$ and $Z_t = \mathbb{B}(t) - \mathbb{B}(t-1)$. With this notation at hand, we get that 
\begin{equation}\label{eq-strongapprox-bound1}
\big| \widetilde{\Phi}_T - \Phi_T^* \big| \le \big| \widetilde{\Phi}_T - \Phi_T^{**} \big| + \big| \Phi_T^{**} - \Phi_T^{*} \big| = \big| \widetilde{\Phi}_T - \Phi_T^{**} \big| + O_p \Big( \sqrt{\frac{\log T}{T}} \Big), 
\end{equation}
where the last equality holds due to the fact that the variables $Z_t$ are independent standard normal and $|\mathcal{G}_T| = O(T^r)$ for some large but fixed constant $r$. Moreover, straightforward calculations yield that 
\[ \big| \widetilde{\Phi}_T - \Phi_T^{**} \big| \le \widehat{\sigma}^{-1} \max_{(u,h) \in \mathcal{G}_T} \big| \widetilde{\phi}_T(u,h) - \phi_T^*(u,h) \big|. \]
Using summation by parts,
%($\sum_{i=1}^n a_i b_i = \sum_{i=1}^{n-1} A_i (b_i - b_{i+1}) + A_n b_n$ with $A_j = \sum_{j=1}^i a_j$) 
we obtain that 
\begin{align*}
\big| \widetilde{\phi}_T(u,h) - \phi_T^*(u,h) \big| 
 & \le \widehat{\sigma}^{-1} W_T(u,h) \max_{1 \le t \le T} \Big| \sum\limits_{s=1}^t \widetilde{\varepsilon}_s - \sigma \sum\limits_{s=1}^t \big\{ \mathbb{B}(s) - \mathbb{B}(s-1) \big\} \Big| \\
 & = \widehat{\sigma}^{-1} W_T(u,h) \max_{1 \le t \le T} \Big| \sum\limits_{s=1}^t \widetilde{\varepsilon}_s - \sigma \mathbb{B}(t) \Big|,
\end{align*}
where
\[ W_T(u,h) = \sum\limits_{t=1}^{T-1} |w_{t+1,T}(u,h) - w_{t,T}(u,h)| + |w_{T,T}(u,h)|. \]
Standard arguments show that $\max_{(u,h) \in \mathcal{G}_T} |W_T(u,h)| = O( 1/\sqrt{Th_{\min}} )$. Applying the strong approximation result \eqref{eq-strongapprox-dep}, we can thus infer that 
\begin{equation}\label{eq-strongapprox-bound2}
\big| \widetilde{\Phi}_T - \Phi_T^{**} \big| \le \widehat{\sigma}^{-1} \max_{(u,h) \in \mathcal{G}_T} \big| \widetilde{\phi}_T(u,h) - \phi_T^*(u,h) \big| = o_p \Big( \frac{T^{1/q}}{\sqrt{Th_{\min}}} \Big). 
\end{equation}
Plugging \eqref{eq-strongapprox-bound2} into \eqref{eq-strongapprox-bound1} completes the proof.



\enlargethispage{0.2cm}
\subsection*{Proof of Proposition \ref{prop2-theo-stat} -- anti-concentration bounds}


The main technical tools for proving Proposition \ref{prop2-theo-stat} are anti-concentration bounds for Gaussian random vectors. The following proposition slightly generalizes anti-concentration results derived in \cite{Chernozhukov2015}, in particular Theorem 3 therein. 
\begin{propA}\label{prop-anticon}
Let $(X_1,\ldots,X_p)^\top$ be a Gaussian random vector in $\reals^p$ with $\ex[X_j] = \mu_j$ and $\var(X_j) = \sigma_j^2 > 0$ for $1 \le j \le p$. Define $\overline{\mu} = \max_{1 \le j \le p} |\mu_j|$ and $a_p = \ex[ \max_{1 \le j \le p} (X_j-\mu_j)/\sigma_j ]$ as well as $\underline{\sigma} = \min_{1 \le j \le p} \sigma_j$ and $\overline{\sigma} = \max_{1 \le j \le p} \sigma_j$. For every $\delta > 0$, it holds that
\[ \sup_{x \in \reals} \pr \Big( \big| \max_{1 \le j \le p} X_j - x \big| \le \delta \Big) \le C \delta \big\{ \overline{\mu} + a_p + \sqrt{1 \vee \log(\underline{\sigma}/\delta)} \big\}, \]
where $C > 0$ depends only on $\underline{\sigma}$ and $\overline{\sigma}$. 
\end{propA} 
To apply Proposition \ref{prop-anticon} to our setting at hand, we introduce the following notation: We write $x_j =(x_{j1},x_{j2}) = (u,h)$ along with $\{x_1,\ldots,x_p\} = \{ x : x \in \mathcal{G}_T \} = \mathcal{G}_T$, where $p := |\mathcal{G}_T| \le O(T^r)$ for some large but fixed $r > 0$ by our assumptions. Moreover, for $j = 1,\ldots,p$, we set 
\[ X_{2j-1} = \frac{\phi_T^*(x_{j1},x_{j2})}{\sigma} - \lambda(x_{j2}) \quad \text{and} \quad X_{2j} = -\frac{\phi_T^*(x_{j1},x_{j2})}{\sigma} - \lambda(x_{j2}). \]
This notation allows us to write
\[ \Phi_T^* = \max_{1 \le j \le 2p} X_j, \]
where $(X_1,\ldots,X_{2p})^\top$ is a Gaussian random vector with the following properties: (i) $\mu_j := \ex[X_j] = - \lambda(x_{j2})$ and thus $\overline{\mu} = \max_{1 \le j \le p} |\mu_j| \le C \sqrt{\log T}$, and (ii) $\var(X_j) = \sigma_j^2$ with $0 < \underline{\sigma} \le \sigma_j \le \overline{\sigma} < \infty$ for some fixed constants $\underline{\sigma}$, $\overline{\sigma}$ that are independent of $T$. Since the variables $(X_j - \mu_j)/\sigma_j$ are standard normal, it holds that $a_p \le \sqrt{2 \log (2p)} \le C \sqrt{\log T}$. With this notation at hand, we can apply Proposition \ref{prop-anticon} to obtain that 
\[ \sup_{x \in \reals} \pr \Big( \big| \Phi_T^* - x \big| \le \delta_T \Big) \le C \delta_T \Big[ \sqrt{\log T} + \sqrt{ \log(\underline{\sigma}/\delta_T) } \Big] = o(1) \]
with $\delta_T = T^{1/q} / \sqrt{T h_{\min}}$, which is the statement of Proposition \ref{prop2-theo-stat}.


\begin{proof}[\textnormal{\textbf{Proof of Proposition \ref{prop-anticon}}}] 
The proof makes use of the following three lemmas, which correspond to Lemmas 5--7 in \cite{Chernozhukov2015}. 
\begin{lemmaA}\label{lemma1-anticon}
Let $(W_1,\ldots,W_p)^\top$ be a (not necessarily centred) Gaussian random vector in $\reals^p$ with $\var(W_j) = 1$ for all $1 \le j \le p$. Suppose that $\text{Corr}(W_j,W_k) < 1$ whenever $j \ne k$. Then the distribution of $\max_{1 \le j \le p} W_j$ is absolutely continuous with respect to Lebesgue measure and a version of the density is given by 
\[ f(x) = f_0(x) \sum\limits_{j=1}^p e^{\ex[W_j]x - (\ex[W_j])^2/2} \, \pr \big(W_k \le x \text{ for all } k \ne j \, \big| \, W_j = x \big). \]
\end{lemmaA}
\begin{lemmaA}\label{lemma2-anticon}
Let $(W_0,W_1,\ldots,W_p)^\top$ be a (not necessarily centred) Gaussian random vector in $\reals^p$ with $\var(W_j) = 1$ for all $0 \le j \le p$. Suppose that $\ex[W_0] \ge 0$. Then the map 
\[ x \mapsto  e^{\ex[W_0]x - (\ex[W_0])^2/2} \, \pr \big(W_j \le x \text{ for } 1 \le j \le p \, \big| \, W_0 = x \big) \]
is non-decreasing on $\reals$. 
\end{lemmaA}
\begin{lemmaA}\label{lemma3-anticon}
Let $(X_1,\ldots,X_p)^\top$ be a centred Gaussian random vector in $\reals^p$ with $\max_{1 \le j \le p} \ex[X_j^2] \le \sigma^2$ for some $\sigma^2 > 0$. Then for any $r > 0$, 
\[ \pr \Big( \max_{1 \le j \le p} X_j \ge \ex \Big[ \max_{1 \le j \le p} X_j \Big] + r \Big) \le e^{-r^2/(2\sigma^2)}. \]
\end{lemmaA} 
The proofs of Lemmas \ref{lemma1-anticon} and \ref{lemma2-anticon} can be found in \cite{Chernozhukov2015}. Lemma \ref{lemma3-anticon} is a standard result on Gaussian concentration which proof is given e.g.\ in \cite{Ledoux2001}; see in particular Theorem 7.1 therein.

We now closely follow the arguments for the proof of Theorem 3 in \cite{Chernozhukov2015}. The proof splits up into three steps. 
\vspace{10pt}


\textit{Step 1.} Pick any $x \ge 0$ and set 
\[ W_j = \frac{X_j - x}{\sigma_j} + \frac{\overline{\mu} + x}{\underline{\sigma}}. \]
By construction, $\ex[W_j] \ge 0$ and $\var(W_j) = 1$. Defining $Z = \max_{1 \le j \le p} W_j$, we have  
\begin{align*}
\pr \Big( \Big| \max_{1 \le j \le p} X_j - x \Big| \le \delta \Big) 
 & \le \pr \Big( \Big| \max_{1 \le j \le p} \frac{X_j - x}{\sigma_j} \Big| \le \frac{\delta}{\underline{\sigma}} \Big) \\
 & \le \sup_{y \in \reals} \pr \Big( \Big| \max_{1 \le j \le p} \frac{X_j - x}{\sigma_j} + \frac{\overline{\mu} + x}{\underline{\sigma}} - y \Big| \le \frac{\delta}{\underline{\sigma}} \Big) \\
 & = \sup_{y \in \reals} \pr \Big( |Z - y| \le \frac{\delta}{\underline{\sigma}} \Big). 
\end{align*}
\vspace{1pt}


\textit{Step 2.} We now bound the density of $Z$. Without loss of generality, we assume that $\text{Corr}(W_j,W_k) < 1$ whenever $k \ne j$. The marginal distribution of $W_j$ is $\normal(\nu_j,1)$ with $\nu_j = \ex[W_j] = (\mu_j/\sigma_j + \overline{\mu}/{\underline{\sigma}}) + (x/\underline{\sigma} - x/\sigma_j) \ge 0$. Hence, by Lemmas \ref{lemma1-anticon} and \ref{lemma2-anticon}, the random variable $Z$ has a density of the form
\begin{equation}\label{eq-dens-Z}
f_p(z) = f_0(z) G_p(z), 
\end{equation}
where the map $z \mapsto G_p(z)$ is non-decreasing. Define $\overline{Z} = \max_{1 \le j \le p} (W_j - \ex[W_j])$ and set $\overline{z} = 2 \overline{\mu}/\underline{\sigma} + x(1/\underline{\sigma} - 1/\overline{\sigma})$ such that $\ex[W_j] \le \overline{z}$ for any $1 \le j \le p$. With these definitions at hand, we obtain that  
\begin{align*}
\int_z^{\infty} f_0(u)du \, G_p(z) & \le \int_z^{\infty} f_0(u) G_p(u) du = \pr(Z > z) \\ 
 & \le P(\overline{Z} > z - \overline{z}) \le \exp \Big( - \frac{(z - \overline{z} - \ex[\overline{Z}])^2_+}{2} \Big), 
\end{align*}
where the last inequality is due to Lemma \ref{lemma3-anticon}. Since $W_j - \ex[W_j] = (X_j - \mu_j)/\sigma_j$, it holds that 
\[ \ex[\overline{Z}] = \ex \Big[ \max_{1 \le j \le p} \Big\{ \frac{X_j-\mu_j}{\sigma_j} \Big\} \Big] =: a_p. \]
Hence, for every $z \in \reals$, 
\begin{equation}\label{eq-bound-Gp}
G_p(z) \le \frac{1}{1 - F_0(z)} \exp\Big( - \frac{(z - \overline{z} - a_p)_+^2}{2} \Big). 
\end{equation}
Mill's inequality states that for $z > 0$, 
\[ z \le \frac{f_0(z)}{1-F_0(z)} \le z \frac{1+z^2}{z^2}. \]
Since $(1+z^2)/z^2 \le 2$ for $z > 1$ and $f_0(z)/\{1-F_0(z)\} \le 1.53 \le 2$ for $z \in (-\infty,1)$, we can infer that
\[ \frac{f_0(z)}{1-F_0(z)} \le 2 (z \vee 1) \quad \text{for any } z \in \reals. \]
This together with \eqref{eq-dens-Z} and \eqref{eq-bound-Gp} yields that
\[ f_p(z) \le 2 (z \vee 1)  \exp\Big( - \frac{(z - \overline{z} - a_p)_+^2}{2} \Big) \quad \text{for any } z \in \reals. \]
\vspace{1pt}
 

\textit{Step 3.} By Step 2, for any $y \in \reals$ and $u > 0$, we have
\[ \pr( |Z - y| \le u) = \int_{y - u}^{y + u} f_p(z) dz \le 2u \max_{z \in [y-u,y+u]} f_p(z) \le 4u (\overline{z} + a_p + 1), \] 
where the last inequality follows from the fact that the map $z \mapsto z e^{-(z-a)^2/2}$ (with $a > 0$) is non-increasing on $[a+1,\infty)$. Combining this bound with Step 1, we get that for any $x \ge 0$ and $\delta > 0$, 
\begin{equation}\label{eq-bound1-Levy}
\pr \Big( \Big| \max_{1 \le j \le p} X_j - x \Big| \le \delta \Big) \le 4\delta \Big\{ \frac{2\overline{\mu}}{\underline{\sigma}} + |x| \Big(\frac{1}{\underline{\sigma}} - \frac{1}{\overline{\sigma}}\Big) + a_p + 1 \Big\} \big/ \underline{\sigma}. 
\end{equation} 
This inequality also holds for $x < 0$ by the analogous argument, and hence for all $x \in \reals$. 


Now let $0 < \delta \le \underline{\sigma}$. For any $|x| \le \delta + \overline{\mu} + \overline{\sigma}(a_p + \sqrt{2\log(\underline{\sigma}/\delta)})$, \eqref{eq-bound1-Levy} yields that 
\begin{align}
\pr \Big( \Big| \max_{1 \le j \le p} X_j - x \Big| \le \delta \Big) 
 & \le \frac{4 \delta}{\underline{\sigma}} \Big\{ \overline{\mu} \Big( \frac{3}{\underline{\sigma}} - \frac{1}{\overline{\sigma}} \Big) + \frac{\overline{\sigma}}{\underline{\sigma}} a_p + \Big( \frac{\overline{\sigma}}{\underline{\sigma}} - 1 \Big) \sqrt{2\log\Big(\frac{\underline{\sigma}}{\delta}\Big)} + 2 - \frac{\underline{\sigma}}{\overline{\sigma}} \Big\} \nonumber \\[0.2cm]
 & \le C \delta \big\{ \overline{\mu} + a_p + \sqrt{1 \vee \log(\underline{\sigma}/\delta)} \big\} \label{eq-bound2-Levy}
\end{align}
with a sufficiently large constant $C > 0$ that depends only on $\underline{\sigma}$ and $\overline{\sigma}$. For \linebreak  $|x| \ge \delta + \overline{\mu} + \overline{\sigma}(a_p + \sqrt{2\log(\underline{\sigma}/\delta)})$, we obtain that 
\begin{equation}\label{eq-bound3-Levy}
\pr \Big( \Big| \max_{1 \le j \le p} X_j - x \Big| \le \delta \Big) \le \frac{\delta}{\underline{\sigma}}, 
\end{equation}
which can be seen as follows: If $x > \delta + \overline{\mu}$, then $|\max_j X_j - x| \le \delta$ implies that $|x| - \delta \le \max_j X_j \le \max_j \{ X_j - \mu_j \} + \overline{\mu}$ and thus $\max_j \{ X_j - \mu_j \} \ge |x| - \delta - \overline{\mu}$. It thus holds that 
\begin{equation}\label{eq-bound3-Levy-prep1}
\pr \Big( \Big| \max_{1 \le j \le p} X_j - x \Big| \le \delta \Big) \le \pr \Big( \max_{1 \le j \le p} \big\{ X_j - \mu_j \} \ge |x| - \delta - \overline{\mu} \Big). 
\end{equation}
If $x < - (\delta + \overline{\mu})$, then $|\max_j X_j - x| \le \delta$ implies that $\max_j \{ X_j - \mu_j \} \le -|x| + \delta + \overline{\mu}$. Hence, in this case,
\begin{align}
\pr \Big( \Big| \max_{1 \le j \le p} X_j - x \Big| \le \delta \Big) 
 & \le \pr \Big( \max_{1 \le j \le p} \big\{ X_j - \mu_j \} \le -|x| + \delta + \overline{\mu} \Big) \nonumber \\
 & \le \pr \Big( \max_{1 \le j \le p} \big\{ X_j - \mu_j \} \ge |x| - \delta - \overline{\mu} \Big), \label{eq-bound3-Levy-prep2}
\end{align}
where the last inequality follows from the fact that for centred Gaussian random variables $Z_j$ and $\forall z > 0$, $\pr(\max_j Z_j \le - z) \le \pr(Z_1 \le -z) = P(Z_1 \ge z) \le \pr(\max_j Z_j \ge z)$. With \eqref{eq-bound3-Levy-prep1} and \eqref{eq-bound3-Levy-prep2}, we obtain that for any $|x| \ge \delta + \overline{\mu} + \overline{\sigma}(a_p + \sqrt{2\log(\underline{\sigma}/\delta)})$,
\begin{align*} 
\pr \Big( & \Big| \max_{1 \le j \le p} X_j - x \Big| \le \delta \Big) \le \pr \Big( \max_{1 \le j \le p} \big\{ X_j - \mu_j \} \ge |x| - \delta - \overline{\mu} \Big) \\
 & \le \pr \Big( \max_{1 \le j \le p} \big\{ X_j - \mu_j \big\} \ge \ex \Big[ \max_{1 \le j \le p} \big\{ X_j-\mu_j \big\} \Big] + \overline{\sigma} \sqrt{2\log(\underline{\sigma}/\delta)} \Big) \le \frac{\delta}{\underline{\sigma}}, 
\end{align*}
the last inequality following from Lemma \ref{lemma3-anticon}. To sum up, we have established that for any $0 < \delta \le \underline{\sigma}$ and any $x \in \reals$, 
\begin{equation}\label{claim-prop-anticon}
\pr \Big( \Big| \max_{1 \le j \le p} X_j - x \Big| \le \delta \Big) \le C \delta \big\{ \overline{\mu} + a_p + \sqrt{1 \vee \log(\underline{\sigma}/\delta)} \big\} 
\end{equation}
with some constant $C > 0$ that does only depend on $\underline{\sigma}$ and $\overline{\sigma}$. For $\delta > \underline{\sigma}$, \eqref{claim-prop-anticon} trivially follows upon setting $C \ge 1/\underline{\sigma}$. This completes the proof. 
\end{proof}



\subsection*{Proof of Corollary \ref{corollary-test-3}}

 
The statement of Corollary \ref{corollary-test-3} is a consequence of the following observation: For all $(u,h) \in \mathcal{G}_T$ with 
\[ \Big|\frac{\widehat{\psi}_T(u,h) - \ex \widehat{\psi}_T(u,h)}{\widehat{\sigma}}\Big| - \lambda(h) \le q_T(\alpha) \quad \text{and} \quad \Big|\frac{\widehat{\psi}_T(u,h)}{\widehat{\sigma}}\Big| - \lambda(h) > q_T(\alpha), \]
it holds that $\ex[\widehat{\psi}_T(u,h)] \ne 0$, which in turn implies that $m(v) \ne 0$ for some $v \in I_{u,h}$. From this observation, we can infer the following: On the event 
\[ \big\{ \widehat{\Phi}_T \le q_T(\alpha) \big\} = \Big\{ \max_{(u,h) \in \mathcal{G}_T} \Big( \Big|\frac{\widehat{\psi}_T(u,h) - \ex \widehat{\psi}_T(u,h)}{\widehat{\sigma}}\Big| - \lambda(h) \Big) \le q_T(\alpha) \Big\}, \]
it holds that for all $(u,h) \in \mathcal{A}_T$, 
$m(v) \ne 0$ for some $v \in I_{u,h}$. Hence, we obtain that 
\[ \big\{ \widehat{\Phi}_T \le q_T(\alpha) \big\} \subseteq E_T. \]
As a result, we arrive at  
\[ \pr(E_T) \ge \pr \big(  \widehat{\Phi}_T \le q_T(\alpha) \big) = (1-\alpha) + o(1), \]
where the last equality holds by Theorem \ref{theo-stat}.
 




\newpage
\bibliographystyle{ims}
{\small
\setlength{\bibsep}{0.55em}
\bibliography{bibliography}}



\end{document}
