\documentclass[a4paper,12pt]{article}
\usepackage{amsmath}
\usepackage{amssymb,amsthm,graphicx}
\usepackage{titlesec}
\usepackage{textcomp}
\usepackage{enumitem}
\usepackage{color}
\usepackage{epsfig}
\usepackage{graphics}
\usepackage{pdfpages}
\usepackage{subcaption}
\usepackage[font=small]{caption}
\usepackage[hang,flushmargin]{footmisc} 
\usepackage{float}
\usepackage{rotating,tabularx}
\usepackage{booktabs}
\usepackage[mathscr]{euscript}
\usepackage{natbib}
\usepackage{setspace}
\usepackage{mathrsfs}
\usepackage[official]{eurosym}
\usepackage[left=2.8cm,right=2.8cm,bottom=2.8cm,top=2.8cm]{geometry}

\setcounter{secnumdepth}{4}
\renewcommand{\baselinestretch}{1.2}
\parindent0pt

\input{macros}



\begin{document}



\begin{center} 
{\large \bf Revision of the paper} \\[0.1cm]
{\large \bf ``Nonparametric comparison of epidemic time trends:} \\[0.1cm]
{\large \bf the case of COVID-19"} 
\end{center}
\vspace{7pt}



First of all, we would like to thank the editor, the associate editor and the reviewers for their comments and suggestions which were very helpful in improving the paper. In the revision, we have addressed all comments and have rewritten the paper accordingly. Please find our point-by-point responses below. %Since the revised paper includes additional material as requested by the referees (additional simulations, a second application example, \dots), it is a bit longer than the original submission. In particular, it has grown from 29 (including Appendix) to ... pages in our layout. However, we are of course happy and willing to reduce the length of the paper if this is needed. 
%Before we reply to the specific comments of the referees, we summarize the major changes in the revision.
In addition to the improvements proposed by the referees, we have extended the application section in two ways: 
\begin{enumerate}[label=(\roman*), leftmargin=0.8cm]

\item As more data on the corona pandemic have become available since the initial submission of the paper, we have additionally run our test on longer time series of $T=200$ days as a robustness check. {\color{red} (Why $T=200$? Explanation needed?)}
%Considering the first $T=200$ days essentially amounts to considering the whole first wave of the pandemic. 
The results are reported in Section S.4 of the Supplementary Material. {\color{red} (We have also changed the time period from $T=139$ to $T=150$ in the application. The results are virtually the same, right? Maybe we should stick to $T=139$ after all. I guess we shouldn't change too many things that are not explicitly asked for.)}  
%We have extended the considered time period from $T = 139$ to $T = 150$ and since now the data are available for longer time period, we perform the robustness check for longer time series with $T = 200$ days and report the results in Section S.4 in the Supplement.

\item In the previous version of the paper, we took the starting date $t=1$ to be the day of the $100$th confirmed case in each country. In the revision, we have slightly changed the definition of the starting date $t=1$ to be the first Monday after reaching $100$ confirmed cases in each country. We have made this change (which was suggested to us by a seminar participant) since there is a strong weekly cycle in the data (presumably due to many unreported cases over the weekend which are reported with delay on Monday). To eliminate possible effects of this weekly cycle, we have aligned the days of the week across countries by starting each time series on a Monday. 

If one compares the old and new data analysis in Section ??, one can see that the test results are essentially unchanged for most countries. Only the pairwise comparisons including the UK are somewhat different. Consider e.g.\ Figures S.2 in the old and the revised supplement: Without the new Monday alignment (old version of Fig.\ S.2), the raw data in the UK and Italy up to approx.\ day $40$ appear to have a somewhat different trending behaviour which is picked up by our test. With the Monday alignment (new version of Fig.\ S.2), a different picture arise. Now the raw data look much more similar over the first $40$ days and our test does not find any deviation from the null up to day $40$. This suggests that not aligning the data by the day of the week may produce some spurious differences across countries. Setting the starting date to be a Monday in each country should take care of this issue. 

We hope you agree with us that this additional alignment is very natural and makes a lot of sense. If not, we are of course happy to switch back to the previous version of the data analysis without this alignment. 

%Comparing the results of our data analysis is essentially unchanged. The only comparisons for which we get different results is the UK. In particular, we ??. We think that the former results were driven by not taking into account the weekly cycvle ion the datza appropriately. 

%In order to make the data even more comparable across countries, we take the starting date $t = 1$ to be the first Monday after reaching 100 confirmed case in each country. Such alignment of the data by starting on Monday takes into account possible differences in reporting the numbers on a weekly level. As a robustness check, we perform our analysis on the time series without the alignment, where we take the starting date $t = 1$ to be the first day after reaching 100 confirmed case in each country, and we report the results of the robustness check in Section S.3 in the Supplement.

\end{enumerate}



%\textbf{Generalization of the theoretical results.} We have extended the theoretical results as suggested by Referee 1:
%\begin{enumerate}[label=(\roman*), leftmargin=0.8cm]

%\item We have derived the following result for the asymptotic power of our test:

%Let the conditions of Theorem A.1 be satisfied and consider two sequences of functions $\lambda_{i, T}$ and $\lambda_{j, T}$ with the following property: There exists $\mathcal{I}_{k} \in \mathcal{F}$ such that 
%\begin{equation}\label{loc-alt}
%\lambda_{i, T}(w) - \lambda_{j, T}(w) \ge c_T \sqrt{\log T / (T h_{k})} \quad \text{for all } w \in \mathcal{I}_{k}, 
%\end{equation}
%where $\{c_T\}$ is any sequence of positive numbers with $c_T \rightarrow \infty$ faster than \linebreak $\frac{\sqrt{\log T}\sqrt{\log \log T}}{\log \log \log T}$. We denote the set of triplets $(i, j, k) \in \indexset$ for which \eqref{loc-alt} holds true as $\indexset_1$. Then 
%\[ \pr\Big( \forall (i,j,k) \in \mathcal{M}_1: |\hat{\psi}_{ijk,T}| > c_{T,\textnormal{Gauss}}(\alpha,h_k) \Big) = 1 - o(1) \]
%for any given $\alpha \in (0, 1)$. 

%This result is stated as Corollary A.2 on p.??  of the revised paper. 

%\end{enumerate}
%\vspace{3pt}

%\textbf{Application.} We have improved the application section in the following way:
%\begin{enumerate}[label=(\roman*), leftmargin=0.8cm]

%\item In order to make the data even more comparable across countries, we take the starting date $t = 1$ to be the first Monday after reaching 100 confirmed case in each country. Such alignment of the data by starting on Monday takes into account possible differences in reporting the numbers on a weekly level. As a robustness check, we perform our analysis on the time series without the alignment, where we take the starting date $t = 1$ to be the first day after reaching 100 confirmed case in each country, and we report the results of the robustness check in Section S.3 in the Supplement.
%\item We have extended the considered time period from $T = 139$ to $T = 150$ and since now the data are available for longer time period, we perform the robustness check for longer time series with $T = 200$ days and report the results in Section S.4 in the Supplement.
%\end{enumerate}
 


\newpage
\begin{center}
{\large \bf Reply to Referee 1} 
\end{center}


Thank you very much for the constructive and helpful comments. In our revision, we have addressed all of them. Please see our replies to your comments below.


\begin{enumerate}[label=(\arabic*),leftmargin=0.7cm]

\item \textit{Since the difference could be canceled out, why should one consider} $\sum\nolimits_t (X_{it} - X_{jt})\mathbf{1}_{t/T \in I_k}$\textit{? Isn't it more appropriate to use} $|X_{it} - X_{jt}|$ \textit{ or } $|X_{it} - X_{jt}|^2$ \textit{to capture the distance?}

Our test statistics $\hat{s}_{ijk,T}$ measure (local) mean distances between the functions $\lambda_i$ and $\lambda_j$. More specifically, for each pair of countries $(i,j)$ and each interval $\mathcal{I}_k$, the statistic
\begin{align*} 
\hat{s}_{ijk,T} 
 & = \frac{1}{\sqrt{Th_k}} \sum\limits_{t=1}^T \ind\Big(\frac{t}{T} \in \mathcal{I}_k\Big) (\X_{it} - \X_{jt}) \\
 & = \frac{1}{Th_k} \sum\limits_{t=1}^T \ind\Big(\frac{t}{T} \in \mathcal{I}_k\Big) \bigg( \lambda_i \Big(\frac{t}{T}\Big)  - \lambda_j \Big(\frac{t}{T}\Big)\bigg) + o_p(1) \\
 & = \sqrt{Th_k} \Big\{ \frac{1}{h_k} \int_{\mathcal{I}_k} (\lambda_i(u) - \lambda_j(u)) du \Big\} + o_p(1) 
\end{align*}
estimates the mean distance 
\[ \Delta_{\text{mean}}(\mathcal{I}_k) := \frac{1}{h_k} \int_{\mathcal{I}_k} (\lambda_i(u) - \lambda_j(u)) du \]
between $\lambda_i$ and $\lambda_j$ on the interval $\mathcal{I}_k$, where $h_k$ is the length of the interval $\mathcal{I}_k$. 
%
%If we only considered one interval $\mathcal{I} \subseteq [0,1]$ (or only a small number of intervals), it would of course not make much sense to use $\Delta_{\text{mean}}$ as a distance measure. Suppose, for example, that we only consider the interval $\mathcal{I} = [0,1]$. In this case, the mean distance 
%\[ \Delta_{\text{mean}}(\mathcal{I}) = \frac{1}{|\mathcal{I}|} \int_{\mathcal{I}} (\lambda_i(u) - \lambda_j(u)) du  = \int_0^1 (\lambda_i(u) - \lambda_j(u)) du \]
%does not give much information on whether the two functions $\lambda_i$ and $\lambda_j$ are different or not: it only allows to say whether they have the same mean. Hence, other distance measures such as the $L_q$ distance  
%\[ \Delta_q(\mathcal{I}) = \frac{1}{|\mathcal{I}|} \int_{\mathcal{I}} |\lambda_i(u) - \lambda_j(u)|^q du \]
%(with, e.g., $q = 1$ or $q=2$) would be more appropriate.
%
%Importantly, however, we do not only consider one interval but a large family of intervals $\{ \mathcal{I}_k: 1 \le k \le K \}$. The local mean differences $\Delta_{\text{mean}}(\mathcal{I}_k)$ are an appropriate distance measure in this situation for the following reason: 
The local mean differences $\Delta_{\text{mean}}(\mathcal{I}_k)$ can be used as a distance measure for the following reason: Suppose the two functions $\lambda_i$ and $\lambda_j$ are continuous (as assumed in the paper). Then $\lambda_i$ and $\lambda_j$ differ from each other on their support $[0,1]$ if and only if there exists a subinterval $\mathcal{I} \subseteq [0,1]$ with $\Delta_{\text{mean}}(\mathcal{I}) \ne 0$. 
%Consequently, we can detect the differences between the functions $\lambda_i$ and $\lambda_j$ by running our test procedure which checks whether $\Delta_{\text{mean}}(\mathcal{I}_k) \ne 0$ for a large number of intervals $\mathcal{I}_k$. This is exactly what our test is doing.  
Consequently, our test procedure, which checks whether $\Delta_{\text{mean}}(\mathcal{I}_k) \ne 0$ for a large number of intervals $\mathcal{I}_k$ simultaneously, should be able to detect the differences between the functions $\lambda_i$ and $\lambda_i$. 
%Consequently, if the family of intervals ?? is rich enough, then we are able to detect the differences between the functions $\lambda_i$ and $\lambda_j$. 
This is reflected in the good power properties of the test which are stated in the new Proposition ??. 

%Indeed, the approach to test whether the local mean $\Delta_{\text{mean}}(\mathcal{I}_k)$ for a large class of intervals $\mathcal{F} = \{ \mathcal{I}_k : 1\le k \le K \}$ is very closely related to (and can be regarded as an extension of)

As you point out completely correctly, one may replace the statistics $\hat{s}_{ijk,T}$ that measure the local mean distances $\Delta_{\text{mean}}(\mathcal{I}_k)$ by statistics that measure local $L_q$ distances $\Delta_q(\mathcal{I}_k)$ of the form 
\[ \Delta_q(\mathcal{I}_k) = \frac{1}{h_k} \int_{\mathcal{I}_k} |\lambda_i(u) - \lambda_j(u)|^q du. \]
Even though this is possible in principle, we follow most other multiscale approaches in the literature which work with local (weighted) mean distances rather than local $L_q$ distances. The reason is mainly technical: The theory in our paper would be quite different if we worked with local $L_q$ distances. 
%To be honest, we do not really know how to conduct the proofs with local $L_q$ distances. 
%The main issue is that we could not make use of the Gaussian approximation results from Chernozhukov ?? as far as we can see. 
In particular, we could not make use of the Gaussian approximation results from \cite{Chernozhukov2017} as far as we can see. 

%\textcolor{red}{We have added some sentences to p.?? of the revision which summarize the discussion above.}   


\item \textit{Now the conclusion will be largely interfered by the choice of interval sets. I am wondering whether we can reach some unified result without the influence of such selection. That is whether we can aggregate the rejected intervals $I_k$ and draw some meaningful conclusion?}

One way to aggregate the rejected intervals $I_k$ is to consider their union. More specifically, one may consider the following quantity: Using the notation from the paper, we let $\mathcal{F}_{\text{reject}}(i,j)$ be the set of rejected intervals for a given pair of countries $(i,j)$ and define the set of minimal intervals by
\[ \mathcal{F}_{\text{reject}}^{\text{min}}(i,j) = \{ \mathcal{I}_k \in \mathcal{F}_{\text{reject}}(i,j): \text{ there exists no } \mathcal{I}_{k^\prime} \in \intervals_{\text{reject}}(i,j) \text{ with } \mathcal{I}_{k^\prime} \subset \mathcal{I}_k \}. \]
%The elements of $\mathcal{F}_{\text{reject}}^{\text{min}}(i,j)$ are called minimal intervals. 
%By definition, there is no other interval $\mathcal{I}_{k^\prime}$ in $\intervals_{\text{reject}}(i,j)$ which is a proper subset of a minimal interval $\mathcal{I}_k$. 
As shown in the new Lemma ?? in the Supplementary Material, the union of minimal intervals
\[ \hat{U}_{ij} = \bigcup_{I \in \mathcal{F}_{\text{reject}}^{\text{min}}(i,j)} I \]
is closely related to the set 
\[ U_{ij} = \{ u \in [0,1]: \lambda_i(u) \ne \lambda_j(u) \}, \] 
that is, to the set of time points where $\lambda_i$ and $\lambda_j$ differ from each other. Under appropriate regularity conditions (as detailed in Corollary ??), one can in particular prove that \begin{equation}\label{eq:Uij}
\pr \Big( \Delta(U_{ij}, \hat{U}_{ij}) \le \nu_T \Big) \ge 1-\alpha + o(1), \tag{$*$}
\end{equation}
where $\Delta(U_{ij},\hat{U}_{ij}) = (U_{ij} \setminus \hat{U}_{ij}) \cup (\hat{U}_{ij} \setminus U_{ij})$ is the symmetric difference between the two sets $U_{ij}$ and $\hat{U}_{ij}$ and $\nu_T \to 0$ as $T \to \infty$. This says that the difference between $U_{ij}$ and $\hat{U}_{ij}$ is small ($\le \nu_T \to 0$) with high probability ($\ge 1 -\alpha + o(1)$). In this sense, $\hat{U}_{ij}$ can be regarded as an approximation of $U_{ij}$. 

{\color{red}
We have added a summary of the above discussion to Section ?? of the paper. The new Lemma ?? and its proof can be found in the Supplementary Material.
}

%Consider a specific pair of countries $(i,j)$ and let $\mathcal{F} = \{ \mathcal{I}_k: 1 \le k \le K \}$ be a large family of intervals. 
%% which in particular covers the whole support $[0,1]$, that is, $\cup_{k=1}^K \mathcal{I}_k = [0,1]$. 
%Moreover, for a given significance level $\alpha \in (0,1)$, let $\mathcal{F}_{\text{reject}}^{\min}(i,j) \subseteq \mathcal{F}$ be the set of minimal intervals as defined in Section ?? of the paper. We could consider the union of intervals in $\mathcal{F}_{\text{reject}}^{\min}(i,j)$, 
%\[ \hat{\mathcal{I}} = \bigcup_{\mathcal{I} \in \mathcal{F}_{\text{reject}}^{\min}(i,j)} \mathcal{I}, \]
%which is a subset of $[0,1]$. According to our theory, we can make the following confidence claim: 
%\begin{itemize}
%\item[($*$)] \textit{With (asymptotic) probability $\ge 1-\alpha$, the functions $\lambda_i$ and $\lambda_j$ differ on the interval $\hat{\mathcal{I}}$.} 
%\end{itemize}
%This confidence statement gives a simpler summary of the test results than the statement (3.7) in the paper according to which the following holds:  
%\begin{itemize}
%\item[($**$)] \textit{With (asymptotic) probability $\ge 1-\alpha$, the functions $\lambda_i$ and $\lambda_j$ differ on any interval $\mathcal{I} \in \mathcal{F}_{\text{reject}}^{\min}(i,j)$.}
%\end{itemize}
%On the other hand, the statement $(**)$ is much more informative than $(*)$. In particular, it allows to pin down more precisely where the differences in the functions are. \textcolor{red}{We have added some discussion on the quantity ${\mathcal{I}}$ and the corresponding confidence statement $(*)$ on p.?? in the revision.} 


\item \textit{The author mentioned this method can be used to identify locations of changes in the trends. But the detail is not very clear to me. For example consider a very simple case: if the two series $i, j$ differ from time $t_1$ to $t_2$ and are the same before and after this interval, where $t_1, t_2, t_2 - t_1$ are all unknown. Can we somehow able to identify this interval $[t_1, t_2]$ using our method and how well can we estimate $t_1$ and $t_2$? If one takes difference of each pair $(i, j)$, and then the trends are zero except some unknown intervals. Then the task is to detect those unknown intervals. Such problem can be possibly solved by for example MOSUM. Can author comments about this?}

As you suggest, we discuss the simple setting where $\lambda_i$ and $\lambda_j$ differ at any time point $t \in (t_1,t_2)$ but are identical at any other time point.
\begin{enumerate}[label=(\roman*),leftmargin=0.75cm]

\item Our method allows to identify differences between the trends $\lambda_i$ and $\lambda_j$ in the sense that we can make confidence statements about where (that is, in which time intervals $I_k$ under consideration) the differences are. In particular, we can make the following confidence statement: 
\vspace{0.1cm}

\begin{center}
\begin{minipage}{0.8\textwidth}
With (asymptotic) probability at least $1-\alpha$, the trends $\lambda_i$ and $\lambda_j$ are different on each interval $\mathcal{I}_k$ for which our test rejects the null $H_0^{(ijk)}$.
\end{minipage}
\end{center} 
\vspace{0.1cm}

Put differently:
\vspace{0.1cm}

\begin{center}
\begin{minipage}{0.8\textwidth}
With (asymptotic) probability at least $1-\alpha$, each interval $\mathcal{I}_k$ for which our test rejects the null $H_0^{(ijk)}$ has some overlap with $(t_1,t_2)$.
\end{minipage}
\end{center}
\vspace{0.1cm}

Hence, the intervals in $\mathcal{F}_{\text{reject}}(i,j)$ for which our test rejects the null give information about where $\lambda_i$ and $\lambda_j$ differ from each other. To summarize the test results, we thus propose to plot the family of intervals $\mathcal{F}_{\text{reject}}(i,j)$. 

\item Our approach does not identify differences between $\lambda_i$ and $\lambda_j$ in the sense that it produces a consistent point estimate of the interval $(t_1,t_2)$. Nevertheless, we conjecture that it is possible to construct a point estimate of $(t_1,t_2)$ based on our approach. More specifically, it should be possible to extend the result \eqref{eq:Uij} discussed in our reply to your previous comment to the case where $\alpha = \alpha_T \to 0$ sufficiently slowly. Hence, we should be able to show that 
\begin{equation}\label{eq:Uij-conjecture}
\pr \Big( \Delta(U_{ij}, \hat{U}_{ij}) \le \nu_T \Big) \ge \underbrace{1-\alpha_T - o(1)}_{= 1 - o(1)}. \tag{$**$}
\end{equation}
This says that $\hat{U}_{ij}$ is a consistent estimator of $U_{ij} = (t_1,t_2)$ in the sense that the difference $\Delta(U_{ij}, \hat{U}_{ij})$ goes to zero (note that $\nu_T \to 0$) with probability tending to $1$. 
\end{enumerate}

Since we are primarily interested in inference rather than point estimation in the paper and since the statement \eqref{eq:Uij-conjecture} is merely a conjecture not covered by our theory, we have decided not to discuss this extension of in the paper. However, we are happy to do so if you think this is needed. 
 


%As suggested by you, we discuss the following simple setting: we consider a specific pair of countries $(i,j)$ and suppose that the functions $\lambda_i$ and $\lambda_j$ differ at any time point $t \in (t_1,t_2)$ but are identical at any other time point $t$. 

%ur methods do not allow us to identify the interval $[t_1,t_2]$ in the sense that it gives a point estimate of it. However, 

%According to Theorem A.1 in the Appendix, our method allows us to make the following confidence statements in this setting: 

%With (asymptotic) probability at least $1-\alpha$, the functions $\lambda_i$ and $\lambda_j$ are different on each interval $\mathcal{I}_k$ for which our test rejects the null $H_0^{(ijk)}$.

%Put differently:

%With (asymptotic) probability at least $1-\alpha$, each interval $\mathcal{I}_k$ for which our test rejects the null $H_0^{(ijk)}$ has some overlap with $(t_1,t_2)$.

%Hence, the collection of intervals for which we reject the null gives information about where the functions $\lambda_i$ and $\lambda_j$ differ. This is why we propose to summarize the test results by plotting the family of intervals $\mathcal{F}_{\text{reject}}(i,j)$ for which our test rejects the null.

%As discussed in our reply to your previous comment, one may alternatively summarize the information contained in the set $\mathcal{F}_{\text{reject}}(i,j)$ by considering the union of minimal intervals $hat{U}_{ij}$. In particular, as argued above, $\hat{U}_{ij}$ is closely related to the interval $U_{ij} = (t_1,t_2)$ in the sense of \eqref{eq:Uij}. 

%Even though we are interested in confidence statements in our paper, it should be possible to construct a point estimate of the interval $[t_1,t_2]$ based on our procedures. We in particular conjecture that the following is possible: We have derived our theory for fixed $\alpha \in (0,1)$. However, it should be possible to extend it to $\alpha = \alpha_T$ with $\alpha_T \to 0$ slowly enough. Moreover, it should be possible to extend the result \eqref{eq:Uij} discussed above to the case with $\alpha_T \to 0$. Hence, we should be able to show that 
%\begin{equation}
%\pr \Big( \Delta(U_{ij}, \hat{U}_{ij}) \le \nu_T \Big) \ge \underbrace{1-\alpha_T - o(1)}_{= 1 - o(1)}.
%\end{equation}
%This says that $\hat{U}_{ij}$ is a consistent estimator of $U_{ij} = [t_1,t_2]$. The precision of the estimator $\hat{U}_{ij}$ is given by $\rho_T$ which is specified in the new Corollary ?? in the SUpplementary Material.  

%As the focus of the paper is inference rather than point estimation, we have decided not to add this discussion to the paper.  

%As suggested by you, we discuss the following simple case: we consider a specific pair of countries $(i,j)$ and suppose that the functions $\lambda_i$ and $\lambda_j$ differ at any time point $t \in [t_1,t_2]$ but are identical at any other time point $t$. Moreover, to simplify the discussion, we assume the following: the interval $[t_1,t_2]$ is fixed (that is, does not change with the sample size $n$), the functions $\lambda_i$ and $\lambda_j$ do not depend on $n$ (that is, we consider a fixed rather than a local alternative), they are continuous and $\lambda_i(t) > \lambda_j(t)$ for all $t \in [t_1,t_2]$.

%Let $\mathcal{L}(S)$ denote the Lebesgue measure of a set $S \subset \reals$ and let $\mathcal{F} = \{\mathcal{I}_k: 1 \le k \le K\}$ be a large family of intervals, which in particular is so rich that the following holds: the intervals in $\mathcal{F}$ with minimal length $h_{\min}$ cover the unit interval $[0,1]$, that is, 
%\[ \bigcup_{\mathcal{I} \in \mathcal{F}_0} \mathcal{I} = [0,1] \quad \text{with} \quad \mathcal{F}_0 = \{ \mathcal{I} \in \mathcal{F}: \mathcal{L}(\mathcal{I}) = h_{\min} \}. \] 
%Under the technical conditions of the paper, we can prove the following: 
%\begin{enumerate}[label=(\roman*)]
%\item With (asymptotic) probability $\ge 1-\alpha$, the test does not reject the null for any interval with $\mathcal{I}_k \cap [t_1,t_2] = \emptyset$. 
%%(i) With (asymptotic) probability $\ge 1-\alpha$, the functions $\lambda_i$ and $\lambda_j$ differ on any interval $\mathcal{I}_k$ for which the test rejects the null. 
%\item With probability tending to $1$, the test rejects the null for any interval $\mathcal{I}_k$ for which $\mathcal{L}(\mathcal{I}_k \cap [t_1,t_2]) \ge h_{\min}/2$.
%\end{enumerate}
%Now let $\mathcal{F}_{\text{reject}}^{\text{min}}(i,j)$ be the set of minimal intervals and let $\hat{\mathcal{I}}$ be their union, that is, $\hat{\mathcal{I}} = \cup_{\mathcal{I} \in \mathcal{F}_{\text{reject}}^{\min}(i,j)} \mathcal{I}$. Then
%\[ \pr \big( [t_1,t_2] \subseteq \hat{I} \big) \ge 1 - \alpha + o(1) \]
%and 
%\[ \pr \big( \mathcal{L} (([t_1,t_2] \setminus \hat{I}) \cap (\hat{I} \cap [t_1,t_2])) \le h_{\min} \big) \ge 1 - \alpha + o(1) \]
%Hence, with (asymptotic) probability $\ge 1-\alpha$, $\mathcal{I}$ covers $[t_1,t_2]$ and it is not much larger that $[t_1,t_2]$ in the sense that the symmetric difference $[t_1,t_2] \setminus \hat{I}) \cap (\hat{I} \cap [t_1,t_2])$ is smaller than the smallest interval length $h_{\min}$.

%The set $\mathcal{I}$ is of course not a consistent estimator of $[t_1,t_2]$. It can rather be interpreted as some sort of confidence set: We know with probability $\ge 1-\alpha$ that $[t_1,t_2]$ is contained in $\mathcal{I}$ and that the set $\mathcal{I}$ is not much larger than $[t_1,t_2]$.


  
%Let us consider the following setting (which is a more detailed version of the simple case that you describe above):
%\begin{itemize}
%\item Consider a specific pair of countries $(i,j)$ and suppose that the functions $\lambda_i$ and $\lambda_j$ differ at any time point $t \in [t_1,t_2]$ but are identical at any other time point $t$. Moreover, suppose the functions $\lambda_i$ and $\lambda_j$ are fixed (that is, we consider a fixed rather than a local alternative), continuous and $\lambda_i(t) > \lambda_j(t)$ for all $t \in [t_1,t_2]$. 
%\item Suppose for simplicity that the family of intervals $\mathcal{F}$ has the following structure:  
%\[ \mathcal{F} = \bigcup_{r=0}^R \mathcal{F}_r \text{ with } \mathcal{F}_r = \Big\{ \big[(\ell-1)h_r,\ell h_r\big]: 1 \le \ell \le h_r^{-1} \text{ and } h_r = 2^r h_{\min} \Big\}.  \]
%where $h_{\min}$ be the minimal interval length which is such that $1/(2h_{\min}) \in \naturals$ and $h_{\min} \to 0$ as $n \to \infty$. Moreover, we suppose that the technical conditions ?? from the paper are satisfied.  
%\item Finally, let the significance level $\alpha = \alpha_n \in (0,1)$ is such that $\alpha\to 0$ as $n \to \infty$. (Our theory can be extended to this case. For simplicity, however, the proofs are written down for fixed $\alpha \in (0,1)$. 
%\end{itemize}
%Let $\mathcal{F}_{\text{reject}}^{\min}(i,j)$ be the set of minimal intervals as defined in Section 3.4 and define 
%\[ \mathcal{I}_{ij} = \bigcup_{\mathcal{I} \in \mathcal{F}_{\text{reject}}^{\min}(i,j)} \mathcal{I} \]
%to be the union of all minimal intervals. It holds that the interval $\mathcal{I}_{ij}$ converges to $[t_1,t_2]$ in the sense that 
%\[ (\mathcal{I}_{ij} \setminus [t_1,t_2]) \cup ([t_1,t_2] \setminus \mathcal{I}_{ij}) \le 2 h_{\min} \quad \text{with probability approaching } 1. \] 


\item \textit{Some theory question}

\begin{enumerate}[label=(\alph*),leftmargin=0.7cm]
\item \textit{Since the result in Chernozukov et al's Gaussian approximation(GA) does not require the series to be independent cross sectionally, I wonder does that mean the current result can be extended to data with cross-sectional dependence?}

In principle, it should be possible to extend our theory to the case of cross-sectional dependence. As far as we can see, our proof strategy should still goes through in this case (even though the technical arguments would of course become more complicated and would need some tweaks here and there). In particular, as you point out, we could still use the Gaussian approximation results of Chernozhukov and coauthors since these do not require cross-sectional dependence. 

It is important to note that we would not only have to adapt the theory to deal with cross-sectional dependence. We would also have to adjust the test procedure itself: Assume that the error terms $\eta_{it}$ in our model are dependent across $i$ (i.e.\ cross-sectionally dependent) but independent across $t$. In this case, the variance of the statistic $\hat{s}_{ijk,T}$ is given by
\begin{align*}
\text{Var}(\hat{s}_{ijk,T}) = \frac{1}{Th_k} \sum_{t=1}^T \boldsymbol{1}\Big(\frac{t}{T} \in \mathcal{I}_k\Big) \bigg\{ \sigma^2 \Big( \lambda_i\Big(\frac{t}{T}\Big) + \lambda_j\Big(\frac{t}{T}\Big) \Big) - C_{ij,T} \bigg\},    
\end{align*}
where the term 
\[ C_{ij,T} = 2 \sigma^2 \sqrt{\lambda_i\Big(\frac{t}{T}\Big)} \sqrt{\lambda_j\Big(\frac{t}{T}\Big)} \mathbb{E}[\eta_{it} \eta_{jt}] \]
reflects the cross-sectional dependence in the data. (In the case of no cross-sectional dependence, $C_{ij,T} = 0$.) To construct the test statistic $\hat{\psi}_{ijk,T}$ of the null hypothesis $H_0^{(ijk)}$, we require an estimator of $\text{Var}(\hat{s}_{ijk,T})$. In order to obtain such an estimator in the case of cross-sectional dependence, we need to estimate the additional term $C_{ij,T}$, which in turn requires us to come up with an estimator of the covariance $\mathbb{E}[\eta_{it} \eta_{jt}] = \text{Cov}(\eta_{it},\eta_{jt})$. 

We have added a footnote to p.?? of the paper which briefly mentions that it is in principle possible to allow for cross-sectional dependencies in the data.

\item \textit{It would be better if the author can derive power under certain alternatives, so that one can get a better idea as how different the trends needs to be in order to be detected.}

As suggested, we have derived the power properties of the test against a certain class of local alternatives. Please see the new Proposition ?? in the Appendix of the paper. The proof is provided in the Supplementary Material.

\item \textit{The argument about no need for time dependent data is reasonable, just a short comment: there already exists result extending Chernozukov et al's GA to time dependent case, maybe this paper can be further extended to time dependent data as well.}

We are aware of extensions of the Gaussian approximation results in \cite{Chernozhukov2013} to the time dependent case. However, we are not aware of any such extensions of the more general Gaussian approximation results in \cite{Chernozhukov2017}, on which our theory is based. 

Specifically, let $x_t = (x_{t,1},\ldots,x_{t,p})^\top$ be $p$-dimensional random vectors for $t=1,\ldots,T$ with $\mathbb{E}[x_t] = 0$ and covariance matrix $\Sigma = \mathbb{E}[x_t x_t^\top]$ and consider the statistics $X_t = (X_{t,1},\ldots,X_{t,p})^\top$ with
\[ X_{t,k} = \frac{1}{\sqrt{T}} \sum_{t=1}^T x_{t,k}. \]
Moreover, let $y_t = (y_{t,1},\ldots,y_{t,p})^\top$ be Gaussian versions of $x_t$ in the sense that $y_t \sim N(0,\Sigma)$ and define $Y_t = (Y_{t,1},\ldots,Y_{t,p})^\top$ with
\[ Y_{t,k} = \frac{1}{\sqrt{T}} \sum_{t=1}^T y_{t,k}. \]
The results in \cite{Chernozhukov2013} allow to bound the distance
\[ \sup_{u \in \mathbb{R}} \Big| \mathbb{P} \big( \max_{1 \le k \le p} X_{t,k} \le u \big) - \mathbb{P} \big( \max_{1 \le k \le p} Y_{t,k} \le u \big) \Big| \]
in the case that the variables $X_t$ are independent across $t$. Generalizations to the case that the $X_t$'s are dependent across $t$ can be found e.g.\ in \cite{ZhangWu2017} and \cite{ZhangCheng2018}. The more general results in \cite{Chernozhukov2017} allow to bound the distance 
\[ \sup_{A \in \mathcal{A}} \Big| \mathbb{P} \big( \max_{1 \le k \le p} X_{t,k} \in A \big) - \mathbb{P} \big( \max_{1 \le k \le p} Y_{t,k} \in A \big) \Big| \]
in the case that the variables $X_t$ are independent across $t$, where $\mathcal{A}$ is the class of hyperrectangles in $\mathbb{R}^p$. This is the type of approximation result on which our proofs are based. As already mentioned above, we are not aware of any extension of this type of result to the time dependent case. (If you know of any such extension, we'd be grateful for the exact reference. With such an extension, we could most probably generalize our results to the time dependent case.) 

\end{enumerate}


\item \textit{The specific allowance of $p = |W|$, which is essential in high dimensional analysis, is not mentioned until appendix. Please put them forward in the main context to provide some guidance in application. Also since the convergence speed of Gaussian approximation depends on $T, p$, it would be better to keep the bound in terms of those parameters, so that we know how large the sample size we need in order to obtain the desired accuracy.}

{\color{red} No idea what's meant here. Do you have any idea?} 

\end{enumerate}



\newpage
\begin{center}
{\large \bf Reply to Referee 2} 
\end{center}


Thank you very much for the constructive and useful suggestions. In our revision, we have addressed all of them. Here are our point-by-point responses to your comments. 


\begin{enumerate}[label=(\arabic*),leftmargin=0.7cm]

\item \textit{The assumption of independence across countries may be debatable, but it seems that in the context of the model, this could be tested, so this may be worth mentioning.}

{\color{red} Check Chapter 12.4.1 on ``Testing Independence between Two Random Variables'' in Li \& Racine, Nonparametric Econometrics for tests on independence. Marina, can you add the references for the tests discussed there? I don't have the book ...} 


\item \textit{Some arguments may be worth further details in the text. For instance, the equation involving} $\hat{s}_{ijk,T} / \sqrt{T h_k}$ \textit{on Page 2 Line 7, or the bound for} $|r_{it}|$ \textit{on Page 2 Line -5.}

As suggested, we have added further details on the statistic $\hat{s}_{ijk,T}$ and the bound for $|r_{it}|$ to the text. Please see the revised Section ?? for the details. We hope you find the changes appropriate.  


\item \textit{I am unsure why the statistic in (3.2) is introduced, I feel the discussion in Pages 8-9 could be done without referring to it.}

The statistic $\hat{\psi}_{ijk,T}^0$ introduced in (3.2) is a modification of the test statistic $\hat{\psi}_{ijk,T}$. It is needed to define the critical values $c_T(\alpha,h_k) = b_k + q_T(\alpha) / a_k$ of the multiscale test in Section ??. Specifically, $\hat{\psi}_{ijk,T}^0$ is required to define the $(1-\alpha)$-quantile $q_T(\alpha)$ of 
\[ \hat{\Psi}_T = \max_{(i,j,k) \in \indexset} a_k \big( |\hat{\psi}_{ijk,T}^0| - b_k \big). \]
For this reason, we have decided not to defer its definition to the Appendix but to introduce it in (3.2) as in the old version of the paper. Otherwise, an important detail of the test would be missing in the main text / would be hidden in the Appendix. We hope you are fine with this. To emphasize that the statistic $\hat{\psi}_{ijk,T}^0$ is required for the definition of the critical values of the multiscale test, we have added the following sentence after its introduction in equation (3.2): ``This statistic is needed to define the critical values of our multiscale test in what follows''.


\item \textit{The "cp." abbreviation is uncommon, I feel it should be replaced by "see" or "e.g."}

As suggested, we have replaced the "cp." abbreviation by "e.g." or "see".
 

\end{enumerate}



\newpage
\bibliographystyle{ims}
{\small
\setlength{\bibsep}{0.45em}
\bibliography{bibliography}}



\end{document}
