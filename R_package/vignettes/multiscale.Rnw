%\VignetteIndexEntry{Multiscale package}
%\VignetteDepends{multiscale}
%\VignetteKeywords{nonparametric time trends}
%\VignettePackage{multiscale}
%\VignetteEngine{knitr::knitr}
%\documentclass[a4paper]{amsart}
%\documentclass[a4paper]{article}
\documentclass[a4paper]{scrartcl}
\usepackage[utf8]{inputenc}
\usepackage{natbib}
\usepackage{url}
\usepackage{amsmath}
%\SweaveOpts{concordance=TRUE}

\title{Multiscale Inference for NonParametric Time Trends}
\author{Marina Khisamtullina \and Michael Vogt}

\begin{document}

\maketitle

\begin{abstract}
We present the R package `multiscale', which performs muliscale tests for nonparametric time trends.
\end{abstract}

\tableofcontents

\section{Introduction}
The main functions of the \textbf{multiscale} package are given in
the following list:
\itemize{
  \item \verb|compute_quantiles()|: Computes the quantiles of the Gaussian version of the statistics 
  that are used to approximate the critical values for the multiscale test; see Sections \ref{sec:single} and \ref{sec:multiple}.
  \item \verb|compute_statistics()|: Computes the value of the test statistics based on a single time series or multiple time series supplied; see Sections \ref{sec:single} and \ref{sec:multiple}.
  \item \verb|multiscale_test()|: Performs the test; see Sections \ref{sec:single} and \ref{sec:multiple}.
  \item \verb|estimate_lrv|: Computes the estimator for the long-run variance of the errors in a nonparametric regression model; see Section \ref{sec:lrv}. 
}

To the best of our knowledge, our \textbf{multiscale} package is the first software
package that offers the estimation methods of \cite{KhismatullinaVogt2019} and \cite{KhismatullinaVogt2020}.

To demonstrate the use of our functions, we analyse two datasets. In order to illustrate the method from \cite{KhismatullinaVogt2019}, we examine the Central England temperature record, which is the longest instrumental temperature time series in the world. The data are publicly available on the webpage of the UK Met Office. A detailed description of the data can be found in \cite{Parker1992}. In order to illustrate the method from \cite{KhismatullinaVogt2020}, we examine the daily number of infections of COVID-19 across different countries. The data are freely available on the homepage of the European Center for Disease Prevention and Control (\texttt{https://www.ecdc.europa.eu}) and were downloaded on 6 July 2020.

The temperature dataset can be obtained from the \textbf{multiscale} package using the function data(temperature,
package = "multiscale"). The COVID-19 dataset can be obtained from the \textbf{multiscale} package using the function data(covid, package = "multiscale").

This vignette is organized as follows. Section \ref{sec:single} presents our mutliscale test for analysing a single time trend as in \cite{KhismatullinaVogt2019} and the results of applying it to the temperature data. Section \ref{sec:multiple} describes the multiscale procedure for comparing different time trends as in \cite{KhismatullinaVogt2020} and displays the results of analysing the COVID-19 data with the help of our test. Section \ref{sec:lrv} introduces the estimator of the long-run variance which is needed for analyzing a nonparametric regression with errors of class AR($p$). Section \ref{sec:concl} concludes.


\section{Multiscale Inference for a Single Nonparametric Regression with Time Series Errors}\label{sec:single}

For our analysis, we use the dataset of yearly mean temperatures which consists of $T=359$ observations $Y_{t,T}$ covering the years from $1659$ to $2017$. A plot of the time series is given in panel (a) of Figure \ref{fig:app:UK}. We assume that the temperature data $Y_{t,T}$ follow the nonparametric trend model $Y_{t,T} = m(t/T) + \varepsilon_t$, where $m$ is the unknown time trend of interest. The error process $\{ \varepsilon_t \}$ is supposed to have the AR($p^*$) structure $\varepsilon_t = \sum_{j=1}^{p^*} a_j \varepsilon_{t-j} + \eta_t$, where $\eta_t$ are i.i.d.\ innovations with mean $0$ and variance $\nu^2$. As pointed out in \cite{Mudelsee2010} among others, this is the most widely used error model for discrete climate time series. We select the AR order $p^*$ by the Bayesian information criterion (BIC), which yields $p^*=2$.\footnote{More precisely, we proceed as follows: We estimate the AR parameters and the corresponding variance of the innovation terms for different AR orders by the methods from Section \ref{sec-error-var} and then choose $p^*$ as the minimizer of the Bayesian information criterion (BIC). As a robustness check, we have repeated this procedure for a wide range of the tuning parameters $q$ and $(\underline{r},\overline{r})$, which produces the value $p^*=2$ throughout. Moreover, we have considered other information criteria such as FPE, AIC and AICC, which gives the AR order $p^*=2$ for almost all values of $q$ and $(\underline{r},\overline{r})$.} We then estimate the AR($2$) parameters $\boldsymbol{a} = (a_1,a_2)$ and the long-run error variance $\sigma^2$ by the procedures from Section \ref{sec-error-var} with $q = 25$ and $(\underline{r},\overline{r}) = (1,10)$. This gives the estimators $\widehat{a}_1 = 0.164$, $\widehat{a}_2 = 0.175$ and $\widehat{\sigma}^2 = 0.737$.
%Order = 2, LRV = 0.737387, a1 = 0.164, a2 = 0.175, sigma_eta^2 = 0.3227605


%\begin{figure}[t!]
%\centering
%\includegraphics[width=0.65\textwidth]{Plots/UK_temperature.pdf}
%\caption{Summary of the results for the Central England temperature record. Panel (a) shows the observed temperature time series. Panel (b) depicts the minimal intervals in the set $\Pi_T^+$ produced by our multiscale test. These are $[1684,1744]$, $[1839,2009]$ and $[1864,2014]$. Panels (c) and (d) present the SiZer maps produced by our multiscale test and SiZer. }\label{fig:app:UK}
%\end{figure}
%

With the help of our multiscale method, we now test the null hypothesis $H_0$ that $m$ is constant on all intervals $[u-h,u+h]$ with $(u,h) \in \mathcal{G}_T^*$, where the grid $\mathcal{G}_T^*$ is defined in the same way as in Section \ref{sec-sim}. The results are presented in Figure \ref{fig:app:UK}. Panel (b) depicts the minimal intervals in the set $\Pi_T^+$ which is produced by our multiscale test $\mathcal{T}_{\text{MS}}$. The set of intervals $\Pi_T^-$ is empty in the present case. 
%The height at which a minimal interval $I_{u,h} = [u-h,u+h] \in \Pi_T^+$ is plotted indicates the value of the corresponding (additively corrected) test statistic $\widehat{\psi}_T(u,h) / \widehat{\sigma} - \lambda(h)$. The dashed line specifies the critical value $q_T(\alpha)$, where $\alpha = 0.05$ as already mentioned above. 
According to Proposition \ref{prop-test-3}, we can make the following simultaneous confidence statement about the collection of minimal intervals plotted in panel (b). We can claim, with confidence of about $95\%$, that the trend $m$ has some increase on each minimal interval. More specifically, we can claim with this confidence that there has been some upward movement in the trend both in the period from around $1680$ to $1740$ and in the period from about $1870$ onwards. Hence, our test in particular provides evidence that there has been some warming trend in the period over approximately the last $150$ years. On the other hand, as the set $\Pi_T^-$ is empty, there is no evidence of any downward movement of the trend.


Panel (c) presents the SiZer map produced by our multiscale test $\mathcal{T}_{\text{MS}}$. For comparison, the SiZer map of the dependent SiZer test $\mathcal{T}_{\text{SiZer}}$ is shown in panel (d). To produce panel (d), we have implemented SiZer as described in Section S.3 of the Supplement, where the autocovariance function of the errors $\{\varepsilon_t\}$ is estimated with the help of our procedures from Section \ref{sec-error-var} under the assumption that $\{\varepsilon_t\}$ is an AR($2$) process. The SiZer maps of panels (c) and (d) are to be read as follows: Each pixel of the map corresponds to a location-scale point $(u,h)$, or put differently, to a time interval $[u-h,u+h]$. The pixel ($u,h)$ is coloured blue if the test indicates an increase in the trend $m$ on the interval $[u-h,u+h]$, red if the test indicates a decrease and purple if the test does not reject the null hypothesis that $m$ is constant on $[u-h,u+h]$. 
%Moreover, a pixel $(u,h)$ is coloured grey if the effective sample size $\text{ESS}^*(u,h)$ is smaller than $5$, in which case the pixel $(u,h)$ is not included in the location-scale grid $\mathcal{G}_T^*$. 
As can be seen, the two SiZer maps in panels (c) and (d) have a similar structure. Both our multiscale test and SiZer indicate increases in the trend $m$ during a short time period around $1700$ and towards the end of the sample. However, in contrast to SiZer, our method allows to make formal confidence statements about the regions of blue pixels in the SiZer map. In particular, as the set of blue pixels in panel (c) exactly corresponds to the collection of intervals $\Pi_T^+$, we can claim, with confidence of about $95\%$, that the trend $m$ has an increase on each time interval represented by a blue pixel in panel (c). 



\section{Multiscale Inference for Multiple Nonparametric Regressions}\label{sec:multiple}

As an illustration for the multiscale method proposed in \cite{KhismatullinaVogt2020}, we analyse the dataset on the daily new cases of infections of COVID-19. The data are freely available on the homepage of the European Center for Disease Prevention and Control (\texttt{https://www.ecdc.europa.eu}) and were downloaded on 17 July 2020. You can load the data using the function data(covid, package = "multiscale").

<<>>=
require(multiscale)
data(covid, package = "multiscale")
head(covid)
@

Each entry in the dataset denotes the number of new cases of infection per day and per country. In our dataset, we have data for $41$ countries and the longest time series consists of $145$ observations.

We assume that the outbreak patterns in different countries follow quasi-Poisson distribution with time-varying intensity parameters. Specifically, we let $X_{it}$ be the number of newly confirmed COVID-19 cases on day $t$ in country $i$ and suppose $X_{it}$ satisfy the following nonparametric regression equation:
\begin{equation}\label{eq:model-intro}
X_{it} = \lambda_i\Big(\frac{t}{T}\Big) + \sigma \sqrt{\lambda_i\Big(\frac{t}{T}\Big)}\eta_{it}, 
\end{equation}
for $1 \le t \le T$ and $1 \le i \le n$, where $\sigma$ is so-called overdispersion parameter that controls the noise variance, and the noise residuals $\eta_{it}$ have zero mean and unit variance. 

In model \eqref{eq:model-intro}, the outbreak pattern of COVID-19 in country $i$ is determined by the intensity function $\lambda_i$. Hence, the question whether the outbreak patterns are comparable across countries amounts to the question whether the intensity functions $\lambda_i$ have the same shape across countries $i$.

In order to make the data comparable across countries, we take the day of the $100$th confirmed case in each country as the starting date $t = 1$. Obviously, for some countries we have longer time series than for the others because the starting point of the outbreak varies across the countries. For the sake of brevity, we present here the analysis only of the data from five European countries: Germany, Italy, Spain, France and the United Kingdom:

<<>>=
covid <- covid[, c("DEU", "GBR", "ESP", "FRA", "ITA")]
covid <- na.omit(covid)
@

As a result, we study $n = 5$ time series of the sample size $T = 134$:

<<>>=
n <- ncol(covid)
t_len <- nrow(covid)
n
t_len
@

Some of the time series contain negative values which we replaced by $0$. Overall, this resulted in $6$ replacements:

<<>>=
sum(covid < 0)
covid[covid < 0] <- 0
@

Here are the plots of the time series:

<<>>=
matplot(1:t_len, covid, type = 'l', lty = 1, col = 1:t_len,
        xlab = 'Number of days since 100th case', ylab = 'cases')
legend("topright", legend = c("DEU", "GBR", "ESP", "FRA", "ITA"),
       inset = 0.02, lty = 1, col = 1:t_len, cex = 0.8)
@

In order to be able to implement the test, we first estimate the overdispersion parameter $\sigma$. For or each country $i$, let 
\begin{align*}
\hat{\sigma}_i^2 = \frac{\sum_{t=2}^T (X_{it}-X_{it-1})^2}{2 \sum_{t=1}^T X_{it}}
\end{align*}
and set $\hat{\sigma}^2 = \frac{1}{n} \sum_{i=1}^n \hat{\sigma}_i^2$. As shown in \cite{KhismatullinaVogt2020}, $\hat{\sigma}^2$ is a consistent estimator of $\sigma^2$ under some regularity conditions. 


<<>>=
sigma_vec <- rep(0, n)
for (i in 1:n){
  diffs <- (covid[2:t_len, i] - covid[1:(t_len - 1), i])
  sigma_squared <- sum(diffs^2) / (2 * sum(covid[, i]))
  sigma_vec[i] <- sqrt(sigma_squared)
}

sigmahat <- sqrt(mean(sigma_vec * sigma_vec))
sigmahat
@

Throughout the section, we set the significance level to $\alpha=0.05$ and the number of the simulations for producing critical values to $5000$:

<<>>=
alpha    <- 0.05
sim_runs <- 5000
@

Furthermore, we compare all pairs of countries $(i,j)$ with $i < j$, and we choose the family of intervals $\mathcal{F}$ for calculating the test statistics as follows. We consider the intervals of lengths $7$ days ($1$ week), $14$ days ($2$ weeks), $21$ days ($3$ weeks), or $28$ days ($4$ weeks). For each length of the interval, we include all intervals that start at days $t = 1 + 7(j-1)$ and $t = 4 + 7(j-1)$ for $j=1,2,\ldots$.

<<>>=
ijset           <- expand.grid(i = 1:n, j = 1:n)
ijset           <- ijset[ijset$i < ijset$j, ]
rownames(ijset) <- NULL
ijset
grid <- construct_weekly_grid(t_len, min_len = 7, nmbr_of_wks = 4) 
@

A graphical presentation of the family $\mathcal{F}$ for our sample size $T = 123$ (as in the application) is given here: 
<<>>=
intervals <- data.frame('left' = grid$gset$u - grid$gset$h,
                        'right' = grid$gset$u + grid$gset$h,
                        'v' = 0)
intervals$v <- (1:nrow(intervals)) / nrow(intervals)

plot(NA, xlim=c(0,t_len),  ylim = c(0, 1 + 1/nrow(intervals)),
     xlab="days", ylab = "", yaxt= "n", mgp=c(2,0.5,0))
title(main = expression(The ~ family ~ of ~ intervals ~ italic(F)),
      line = 1)
segments(intervals$left * t_len, intervals$v,
         intervals$right * t_len, intervals$v,
         lwd = 2)
@

With the help of our multiscale method, we simultaneously test the null hypothesis $H_0^{(i, j, k)}$ that $\lambda_i(\cdot) = \lambda_j(\cdot)$ on the interval $\mathcal{I}_k \in \mathcal{F}$ for each $(i, j, k)$. We denote the length of the intervals from the grid as $h_k$. 

Now we are ready to perfrom the test.
\enumerate{
  \item Compute the quantile $q_{T,\text{Gauss}}(\alpha)$ by Monte Carlo simulations. Specifically, draw a large number $\verb|sim_runs| = 5000$ samples of independent standard normal random variables $\{Z_{it}^{(\ell)} : 1 \le i \le n, \, 1 \le t \le T \}$ for $1 \le \ell \le \verb|sim_runs|$. Compute the value $\Phi_T^{(\ell)}$ of the Gaussian statistic $\Phi_T$ for each sample $\ell$ by the following formula:
\begin{align*}
\Phi_T = \max_{(i,j,k)} a_k \big( |\phi_{ijk,T}| - b_k \big),
\end{align*}
where
\begin{align*}
\phi_{ijk,T} = \frac{1}{\sqrt{2Th_k}} \sum\limits_{t=1}^T \mathbf{1}\Big(\frac{t}{T} \in \mathcal{I}_k\Big) \big\{ Z_{it} - Z_{jt} \big\},
\end{align*}
$a_k = \{\log(e/h_k)\}^{1/2} / \log \log(e^e / h_k)$ and $b_k = \sqrt{2 \log(1/h_k)}$. Then calculate the empirical $(1-\alpha)$-quantile $\hat{q}_{T,\text{Gauss}}(\alpha)$ from the values $\{ \Phi_T^{(\ell)}: 1 \le \ell \le \verb|sim_runs| \}$. Use $\hat{q}_{T,\text{Gauss}}(\alpha)$ as an approximation of the quantile $q_{T,\text{Gauss}}(\alpha)$.

This step is done with these lines of code:

<<>>=
quantiles <- compute_quantiles(t_len = t_len, grid = grid,
                               n_ts = n, ijset = ijset,
                               sigma = sigmahat,
                               sim_runs = sim_runs)

probs <- as.vector(quantiles$quant[1, ])
pos   <- which.min(abs(probs - (1 - alpha)))
quant <- quantiles$quant[2, pos]
quant
@

}




The results are presented in Figures \ref{fig:Germany:Italy}--\ref{fig:Germany:UK}, each figure comparing a specific pair of countries $(i,j)$ from our sample. For the sake of brevity, we only show the results for the pairwise comparisons of Germany with each of the four other countries. The remaining figures can be found in Section \ref{s:subsec:app} of the Supplementary Material. Each figure splits into four panels (a)--(d).  Panel (a) shows the observed time series for the two countries $i$ and $j$ that are compared. Panel (b) presents smoothed versions of the time series from (a), that is, it shows nonparametric kernel estimates of the two trend functions $\lambda_i$ and $\lambda_j$, where the bandwidth is set to $7$ days and a rectangular kernel is used. Panel (c) displays the Government Response Index (GRI) of the two countries. Finally, panel (d) presents the results produced by our test. Specifically, it depicts in grey the set $intervals_{\text{reject}}(i,j)$ of all the intervals $\mathcal{I}_k$ for which the test rejects the null $H_0^{(i, j, k)}$. The minimal intervals in the subset $intervals_{\text{reject}}^{\text{min}}(i, j)$ are depicted in black. Note that according to \eqref{eq:simconfstat}, we can make the following simultaneous confidence statement about the intervals plotted in panels (d) of Figures \ref{fig:Germany:Italy}--\ref{fig:Germany:UK}: we can claim, with confidence of about $95\%$, that there is a difference between the functions $\lambda_i$ and $\lambda_j$ on each of these intervals.


\section{Long-run variance estimator}\label{sec:lrv}
\bibliography{bibliography.bib}
\bibliographystyle{ims}
\end{document}